{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4c00968-ba66-4ded-9a51-6152f5846a4b",
   "metadata": {},
   "source": [
    "# Initalize libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da40b57-6467-45ee-b067-3d55970bcdba",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b382e993-0486-4546-a4a0-1a91155e4853",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import gc\n",
    "import time\n",
    "from os.path import join\n",
    "from os import path\n",
    "from importlib import reload\n",
    "from getpass import getuser\n",
    "from glob import glob\n",
    "from tqdm.auto import tqdm\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "# Data\n",
    "import xarray as xr\n",
    "import h5py\n",
    "import numpy as np\n",
    "from nexusformat.nexus import *\n",
    "from sfdata import SFDataFiles\n",
    "\n",
    "# Plotting\n",
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "import fabio\n",
    "import skimage.morphology\n",
    "\n",
    "# skimage\n",
    "from skimage.draw import ellipse\n",
    "\n",
    "# scipy\n",
    "from scipy.ndimage.filters import gaussian_filter\n",
    "import scipy\n",
    "from scipy import stats\n",
    "\n",
    "# pyFAI\n",
    "import pyFAI\n",
    "from pyFAI.azimuthalIntegrator import AzimuthalIntegrator\n",
    "from pyFAI.detectors import Detector\n",
    "\n",
    "# Self-written libraries\n",
    "sys.path.append(join(os.getcwd(), \"library\"))\n",
    "#import phrcore\n",
    "import mask_lib\n",
    "import reconstruct as reco\n",
    "import fthcore as fth\n",
    "import support_functions as sup\n",
    "import interactive\n",
    "from interactive import cimshow\n",
    "import reconstruct_rb as rec\n",
    "import reconstruct as reco\n",
    "\n",
    "plt.rcParams[\"figure.constrained_layout.use\"] = True  # replaces plt.tight_layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef13f839-af3a-4b32-83cf-722ac1a68313",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Is there a GPU?\n",
    "try:\n",
    "    # Cupy\n",
    "    import cupy as cp\n",
    "    import cupyx as cpx\n",
    "\n",
    "    GPU = True\n",
    "\n",
    "    print(\"GPU available\")\n",
    "\n",
    "    # Self-written library\n",
    "    import CCI_core_cupy as cci\n",
    "    import Phase_Retrieval as PhR\n",
    "except:\n",
    "    GPU = False\n",
    "    import CCI_core as cci\n",
    "\n",
    "    print(\"GPU unavailable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f61d0fb-7ee5-44b4-9298-19fe6324abda",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "GPU = False\n",
    "import CCI_core as cci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2da438-226a-47d5-91b8-f5acc9664aa0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# interactive plotting\n",
    "import ipywidgets\n",
    "\n",
    "%matplotlib widget\n",
    "\n",
    "# Auto formatting of cells\n",
    "%load_ext jupyter_black"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3408ae5-de64-411e-a3e3-f926b19134ab",
   "metadata": {},
   "source": [
    "## Experiment specific Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4ef2fe-75cd-44f1-a728-5754a45422c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "BEAMTIMEID = 21626\n",
    "USER = getuser()\n",
    "\n",
    "# Number or jobs for analysis\n",
    "NR_JOBS = 16\n",
    "\n",
    "BASEFOLDER = f\"/das/home/{USER}/p{BEAMTIMEID}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e069c0b9-a273-43c1-8b00-d704b485608f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mnemonics = dict()\n",
    "mnemonics[\"Photon-Energy-PER-PULSE-AVG\"] = \"SATFE10-PEPG046:PHOTON-ENERGY-PER-PULSE-AVG\"\n",
    "mnemonics[\"images\"] = \"SATES20-HOLO-CAM01:FPICTURE\"\n",
    "mnemonics[\"APD\"] = \"SATES21-GES1:A2_VALUES\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "516a8482-bd49-4257-9661-3f9639aa23e8",
   "metadata": {},
   "source": [
    "### Loading, saving fth & cdi data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be71f004-0fd2-4228-b0e4-eb4ed1ae69a1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def frame_list_to_acq_and_idx(frame_list, stack_length):\n",
    "    \"\"\"\n",
    "    Convert a continous list of frame index that span multiple acq stacks into\n",
    "    its corresponding acq numbers and frames, e.g. for stack_length = 100:\n",
    "    frame_list = [99,100,101] --> acq_nrs = [1,2], frame_index_list = [[99],[0,1]]\n",
    "    \"\"\"\n",
    "    # Calc quotient of frame_list and acq stack length to find relevant acq idx\n",
    "    acq_idx = np.array(np.divmod(frame_list, stack_length))\n",
    "\n",
    "    # Setup lists\n",
    "    acq_nrs = []\n",
    "    frame_index_list = []\n",
    "\n",
    "    # Group frames that correspond to identical acq_stackd to minimize data access\n",
    "    for i in np.unique(acq_idx[0]):\n",
    "        acq_nrs.append(i + 1)  # First stack is acq0001\n",
    "        frame_idx = np.where(acq_idx[0] == i)\n",
    "        frame_index_list.append(acq_idx[1][frame_idx])\n",
    "\n",
    "    return np.array(acq_nrs), frame_index_list\n",
    "\n",
    "\n",
    "def list_data_filenames(run_nr, search_key=\"*\"):\n",
    "    \"\"\"\n",
    "    Returns a list of ALL data files that correspond to the\n",
    "    given run number and contain the search key\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert run number to string\n",
    "    if type(run_nr) == int:\n",
    "        run_nr = \"*%04d*\" % run_nr\n",
    "\n",
    "    # Find folder that corresponds to run number\n",
    "    folder = glob(join(BASEFOLDER, \"raw\", run_nr))[0]\n",
    "    print(\"Found folder: %s\" % folder)\n",
    "\n",
    "    # Get sorted list of files in folder\n",
    "    files = sorted(glob(join(folder, \"data\", search_key)))\n",
    "\n",
    "    return files, folder\n",
    "\n",
    "\n",
    "def list_acquisition_filenames(run_nr, acq_nrs=[], ONLY_CAMERA=False):\n",
    "    \"\"\"\n",
    "    Returns a list of data files for the given acquisition\n",
    "    numbers\n",
    "    \"\"\"\n",
    "\n",
    "    # Load only camera files?\n",
    "    if ONLY_CAMERA:\n",
    "        search_key = \"*CAMERAS.h5\"\n",
    "    else:\n",
    "        search_key = \"*\"\n",
    "\n",
    "    # If for run_nr is only gives a int number\n",
    "    if type(run_nr) == int:\n",
    "        run_nr = \"*%04d*\" % run_nr\n",
    "\n",
    "    # If list is empty all files are loaded, only specific acquisition nrs\n",
    "    # otherwise\n",
    "    if len(acq_nrs) == 0:\n",
    "        fnames, _ = list_data_filenames(run_nr, search_key=search_key)\n",
    "    elif len(acq_nrs) > 0:\n",
    "        _, folder = list_data_filenames(run_nr, search_key=search_key)\n",
    "\n",
    "        fnames = []\n",
    "        for acq_nr in acq_nrs:\n",
    "            acq_str = f\"*{acq_nr:04d}{search_key}\"\n",
    "\n",
    "            # Get filename pattern\n",
    "            fname_pattern = join(\n",
    "                folder,\n",
    "                \"data\",\n",
    "                acq_str,\n",
    "            )\n",
    "\n",
    "            fnames.append(glob(fname_pattern))\n",
    "\n",
    "    # Flatten potential nested list\n",
    "    fnames_flattened = flatten_list(fnames)\n",
    "\n",
    "    return fnames_flattened\n",
    "\n",
    "\n",
    "def load_run(fnames, mnemonics):\n",
    "    \"\"\"\n",
    "    Load all relevant data that are specified in the mnemonics dict (bugged)\n",
    "    \"\"\"\n",
    "\n",
    "    data = dict()\n",
    "    N = len(fnames)\n",
    "\n",
    "    with SFDataFiles(fnames[0]) as f:\n",
    "        for key in mnemonics.keys():\n",
    "            try:\n",
    "                data[key] = f[mnemonics[key]].data\n",
    "            except:\n",
    "                pass\n",
    "    if N > 1:\n",
    "        for fname in tqdm(fnames[1:]):\n",
    "            with SFDataFiles(fname) as f:\n",
    "                for key in mnemonics.keys():\n",
    "                    try:\n",
    "                        data[key] = np.concatenate((data[key], f[mnemonics[key]].data))\n",
    "                    except:\n",
    "                        pass\n",
    "    return data\n",
    "\n",
    "\n",
    "def load_images(fnames, loadmode=\"avg\", n_jobs=1, crop=0):\n",
    "    \"\"\"\n",
    "    Loads images from list of filenames\n",
    "    \"\"\"\n",
    "\n",
    "    # Setup\n",
    "    images = []\n",
    "    N = len(fnames)\n",
    "\n",
    "    # Cropping necessary?\n",
    "    if crop == 0:\n",
    "        slice_crop = slice(0, -1)\n",
    "    else:\n",
    "        slice_crop = slice(crop, -crop)\n",
    "\n",
    "    # Define loader function based on required loadmode\n",
    "    if loadmode == \"frames\":\n",
    "\n",
    "        def loader(fname):\n",
    "            with SFDataFiles(fnames[0]) as f:\n",
    "                image_stack = f[mnemonics[\"images\"]][:, slice_crop, slice_crop].data\n",
    "            return image_stack\n",
    "\n",
    "    elif loadmode == \"avg\":\n",
    "\n",
    "        def loader(fname):\n",
    "            with SFDataFiles(fname) as f:\n",
    "                image = np.mean(\n",
    "                    f[mnemonics[\"images\"]][:, slice_crop, slice_crop].data, axis=0\n",
    "                )\n",
    "            return image\n",
    "\n",
    "    print(f\"Start loading images with {n_jobs} parallel processes.\")\n",
    "    t0 = time.time()\n",
    "    images = Parallel(n_jobs=n_jobs, verbose=10)(\n",
    "        delayed(loader)(fname) for fname in fnames\n",
    "    )\n",
    "    print(f\"Elapsed time: {time.time()-t0} seconds.\")\n",
    "\n",
    "    return np.array(drop_inhomogenous_part(images))\n",
    "\n",
    "\n",
    "def load_specific_frames(fnames, indexes, crop=0):\n",
    "    \"\"\"\n",
    "    Load only specific frames for a list of filenames\n",
    "    \"\"\"\n",
    "\n",
    "    # Setup\n",
    "    images = []\n",
    "\n",
    "    # Cropping necessary?\n",
    "    if crop == 0:\n",
    "        slice_crop = slice(0, -1)\n",
    "    else:\n",
    "        slice_crop = slice(crop, -crop)\n",
    "\n",
    "    # Loop over different fnames and indices\n",
    "    for i, fname in enumerate(fnames):\n",
    "        # Load only relevant frames from file\n",
    "        with SFDataFiles(fname) as f:\n",
    "            image = f[mnemonics[\"images\"]][indexes[i], slice_crop, slice_crop].data\n",
    "        images.append(image)\n",
    "\n",
    "    return np.vstack(images)\n",
    "\n",
    "\n",
    "# Full image loading procedure\n",
    "def load_processing_frames(fnames, loadmode=\"avg\", crop=0, frame_index_list=[]):\n",
    "    \"\"\"\n",
    "    Loads images, calc average over all images,\n",
    "    padding to square shape, Additional cropping (optional)\n",
    "    \"\"\"\n",
    "    # Basic loading of stacks into list\n",
    "    if not frame_index_list:\n",
    "        images = load_images(fnames, loadmode, n_jobs=NR_JOBS, crop=crop)\n",
    "    else:\n",
    "        images = load_specific_frames(fnames, frame_index_list, crop=crop)\n",
    "\n",
    "    # Bring to square shape\n",
    "    images = make_square_shape(images)\n",
    "    gc.collect()\n",
    "\n",
    "    # Calculate mean\n",
    "    if images.ndim > 2:\n",
    "        image = np.mean(images, axis=0)\n",
    "    else:\n",
    "        image = images.copy()\n",
    "\n",
    "    return image, images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0849b7ad-ebb8-43fc-98ad-82300d4d01ff",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save_cdi_h5():\n",
    "    # Save h5\n",
    "    data = {}\n",
    "    data[\"im_id\"] = im_id\n",
    "    data[\"topo_id\"] = topo_id\n",
    "    data[\"pos\"] = pos\n",
    "    data[\"neg\"] = neg\n",
    "    data[\"factor\"] = factor\n",
    "    data[\"offset\"] = offset\n",
    "    data[\"center\"] = center\n",
    "    data[\"roi\"] = roi_cdi\n",
    "    data[\"prop_dist\"] = prop_dist_cdi\n",
    "    data[\"phase\"] = phase_cdi\n",
    "    data[\"mask_bs\"] = mask_bs_cdi\n",
    "    data[\"supportmask\"] = supportmask\n",
    "    data[\"mask_pixel\"] = mask_pixel.astype(bool)\n",
    "    data[\"p\"] = p\n",
    "    data[\"n\"] = n\n",
    "    data[\"p_pc\"] = p_pc\n",
    "    data[\"n_pc\"] = n_pc\n",
    "    data[\"experimental_setup\"] = experimental_setup\n",
    "\n",
    "    filename = join(\n",
    "        folder_target,\n",
    "        \"Logs\",\n",
    "        \"Data_ImId_%s_RefId_%s_cdi_%s\"\n",
    "        % (\n",
    "            im_id,\n",
    "            topo_id,\n",
    "            USER,\n",
    "        ),\n",
    "    )\n",
    "    print(\"Now Saving: %s\" % filename)\n",
    "    cci.create_hdf5(data, filename)\n",
    "    return\n",
    "\n",
    "\n",
    "# Saving of log files for fth and cdi recos\n",
    "def save_fth_h5():\n",
    "    # Save h5\n",
    "    data = {}\n",
    "    data[\"im_id\"] = im_id\n",
    "    data[\"topo_id\"] = topo_id\n",
    "    data[\"topo_centered\"] = topo_c\n",
    "    data[\"im_centered\"] = im_c\n",
    "    data[\"holo\"] = holo\n",
    "    data[\"recon\"] = recon\n",
    "    data[\"factor\"] = factor\n",
    "    data[\"offset\"] = offset\n",
    "    data[\"center\"] = center\n",
    "    data[\"roi\"] = roi\n",
    "    data[\"prop_dist\"] = prop_dist\n",
    "    data[\"phase\"] = phase\n",
    "    data[\"mask_bs\"] = mask_bs\n",
    "    data[\"mask_pixel\"] = mask_pixel.astype(bool)\n",
    "    data[\"mask_draw\"] = mask_draw.astype(bool)\n",
    "    data[\"mask_pixel_smooth\"] = mask_pixel_smooth\n",
    "    data[\"experimental_setup\"] = experimental_setup\n",
    "\n",
    "    filename = join(\n",
    "        folder_target,\n",
    "        \"Logs\",\n",
    "        \"Data_ImId_%s_RefId_%s_%s\"\n",
    "        % (\n",
    "            im_id,\n",
    "            topo_id,\n",
    "            USER,\n",
    "        ),\n",
    "    )\n",
    "    print(\"Now Saving: %s\" % filename)\n",
    "    cci.create_hdf5(data, filename)\n",
    "\n",
    "\n",
    "def load_fth(im_id, topo_id):\n",
    "    \"\"\"\n",
    "    Load fth dataset\n",
    "    \"\"\"\n",
    "    fname = join(\n",
    "        folder_target,\n",
    "        \"Logs\",\n",
    "        \"Data_ImId_%s_RefId_%s_%s.hdf5\"\n",
    "        % (\n",
    "            im_id,\n",
    "            topo_id,\n",
    "            USER,\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    with h5py.File(fname, \"r\") as f:\n",
    "        data = {}\n",
    "        for key in f.keys():\n",
    "            if key != \"experimental_setup\":\n",
    "                data[key] = f[key][()]\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def save_cdi_h5():\n",
    "    # Save h5\n",
    "    data = {}\n",
    "    data[\"im_id\"] = im_id\n",
    "    data[\"topo_id\"] = topo_id\n",
    "    data[\"pos\"] = pos\n",
    "    data[\"neg\"] = neg\n",
    "    data[\"factor\"] = factor\n",
    "    data[\"offset\"] = offset\n",
    "    data[\"center\"] = center\n",
    "    data[\"prop_dist\"] = prop_dist_cdi\n",
    "    data[\"phase\"] = phase_cdi\n",
    "    data[\"mask_bs\"] = mask_bs_cdi\n",
    "    data[\"supportmask\"] = supportmask\n",
    "    data[\"mask_pixel\"] = mask_pixel\n",
    "    # data[\"p\"] = p\n",
    "    # data[\"n\"] = n\n",
    "    data[\"p_pc\"] = p_pc\n",
    "    data[\"n_pc\"] = n_pc\n",
    "    data[\"experimental_setup\"] = experimental_setup\n",
    "\n",
    "    filename = join(\n",
    "        folder_target,\n",
    "        \"Logs\",\n",
    "        \"Data_ImId_%s_RefId_%s_cdi_%s\"\n",
    "        % (\n",
    "            im_id,\n",
    "            topo_id,\n",
    "            USER,\n",
    "        ),\n",
    "    )\n",
    "    print(\"Now Saving: %s\" % filename)\n",
    "    cci.create_hdf5(data, filename)\n",
    "    return\n",
    "\n",
    "\n",
    "def save_topo_holo(topo_c, pos_id, neg_id):\n",
    "    \"\"\"\n",
    "    Save only topo holos which can be later used for single helicity reconstructions\n",
    "    \"\"\"\n",
    "    data = {}\n",
    "    data[\"pos_id\"] = pos_id\n",
    "    data[\"neg_id\"] = neg_id\n",
    "    data[\"topo\"] = sum_c\n",
    "\n",
    "    filename = join(\n",
    "        folder_target,\n",
    "        \"Topos\",\n",
    "        \"Topo_ImId_%s_RefId_%s_cdi_%s\" % (pos_id, neg_id, USER),\n",
    "    )\n",
    "    print(\"Now Saving: %s\" % filename)\n",
    "    cci.create_hdf5(data, filename)\n",
    "    return\n",
    "\n",
    "\n",
    "def load_topo_holo(pos_id, neg_id):\n",
    "    \"\"\"\n",
    "    Load topo holos for single helicity reconstructions\n",
    "    \"\"\"\n",
    "    fname = join(\n",
    "        folder_target,\n",
    "        \"Topos\",\n",
    "        \"Topo_ImId_%s_RefId_%s_cdi_%s.hdf5\" % (pos_id, neg_id, USER),\n",
    "    )\n",
    "\n",
    "    with h5py.File(fname, \"r\") as f:\n",
    "        im_out = f[\"topo\"][()]\n",
    "    return im_out\n",
    "\n",
    "\n",
    "def load_cdi(im_id, topo_id):\n",
    "    \"\"\"\n",
    "    Load cdi dataset\n",
    "    \"\"\"\n",
    "    fname = join(\n",
    "        folder_target,\n",
    "        \"Logs\",\n",
    "        \"Data_ImId_%s_RefId_%s_cdi_%s.hdf5\" % (im_id, topo_id, USER),\n",
    "    )\n",
    "\n",
    "    with h5py.File(fname, \"r\") as f:\n",
    "        data = {}\n",
    "        for key in f.keys():\n",
    "            if key != \"experimental_setup\":\n",
    "                data[key] = f[key][()]\n",
    "\n",
    "    return data_cdi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a54f4111-79ad-42a5-a0de-3a2735771a04",
   "metadata": {},
   "source": [
    "### Other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2595b799-939c-4d22-9712-79c71ab5bba8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def drop_inhomogenous_part(image_list):\n",
    "    # Find length of all image_list stacks\n",
    "    length = np.array([im.shape[0] for im in image_list])\n",
    "    max_stack_size = np.min(length)\n",
    "\n",
    "    # Check if array is inhomogenous\n",
    "    if np.all(length == max_stack_size) is False:\n",
    "        print(\"Dropping inhomogenous part of array\")\n",
    "        for i in range(len(image_list)):\n",
    "            image_list[i] = image_list[i][:max_stack_size]\n",
    "\n",
    "    return image_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc07123-abcc-4a54-943b-60a3504d88b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def flatten_list(nested_list):\n",
    "    flat_list = []\n",
    "    for item in nested_list:\n",
    "        if isinstance(item, list):\n",
    "            flat_list.extend(flatten_list(item))\n",
    "        else:\n",
    "            flat_list.append(item)\n",
    "    return flat_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e6ccbf-a10c-4f8c-9298-bbcedb0ffad7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_square_shape(images):\n",
    "    crop = np.min(np.array([images.shape[-2], images.shape[-1]]))\n",
    "    images = images[..., :crop, :crop]\n",
    "\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f3d9fd2-9f04-480e-9088-9b16b98d501c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Worker which performs complete fth reconstruction process\n",
    "def worker(image, topo):\n",
    "    # Centering\n",
    "    shift_c = np.array(topo.shape) / 2 - center\n",
    "    topo_c = cci.shift_image(topo, shift_c)\n",
    "    im_c = cci.shift_image(image, shift_c)\n",
    "\n",
    "    ## Image registration\n",
    "    shift = cci.image_registration(\n",
    "        im_c[roi_im_reg],\n",
    "        topo_c[roi_im_reg],\n",
    "        method=\"dipy\",\n",
    "    )\n",
    "\n",
    "    # shift = [0, 0]\n",
    "    print(\"Relative shift is: %s\" % shift)\n",
    "\n",
    "    # Correct relative drift\n",
    "    topo_c = cci.shift_image(topo_c, shift)\n",
    "\n",
    "    # Create masks\n",
    "    # Create image specific beamstop mask\n",
    "    mask_im = mask_draw.copy()\n",
    "    mask_im = mask_im + (im_c > experimental_setup[\"int_cutoff\"])\n",
    "    mask_im[mask_im > 1] = 1\n",
    "\n",
    "    # Create topo specific beamstop mask\n",
    "    mask_topo = mask_draw.copy()\n",
    "    mask_topo = mask_topo + (topo_c > experimental_setup[\"int_cutoff\"])\n",
    "\n",
    "    # Combine both\n",
    "    mask_pixel = mask_im + mask_topo\n",
    "    mask_pixel[mask_pixel > 1] = 1\n",
    "\n",
    "    # Create smooth mask\n",
    "    footprint = skimage.morphology.disk(6)\n",
    "    mask_pixel_smooth = skimage.morphology.dilation(mask_pixel, footprint)\n",
    "    mask_pixel_smooth = gaussian_filter(mask_pixel_smooth, 2)\n",
    "\n",
    "    # Get scaling factor and offset\n",
    "    factor, offset = cci.dyn_factor(\n",
    "        im_c * (1 - mask_pixel),\n",
    "        topo_c * (1 - mask_pixel),\n",
    "        method=\"correlation\",\n",
    "        print_out=False,\n",
    "        plot=False,\n",
    "    )\n",
    "\n",
    "    # Calculate differences (magnetic) and sums (topographc) contrast holograms.\n",
    "    # _c: centered, without beamstop, _b: centered, with beamstop\n",
    "    diff_c = im_c / factor - topo_c - offset\n",
    "    diff_b = diff_c * mask_bs\n",
    "    sum_c = im_c / factor + topo_c - offset\n",
    "    sum_b = sum_c * mask_bs\n",
    "\n",
    "    # holo = sum_c * mask_bs*(1 - mask_pixel_smooth)\n",
    "    holo = diff_c * mask_bs * (1 - mask_pixel_smooth)\n",
    "\n",
    "    # Reconstruct\n",
    "    recon = cci.reconstruct(\n",
    "        fth.propagate(holo, prop_dist * 1e-6, experimental_setup=experimental_setup)\n",
    "        * np.exp(1j * phase)\n",
    "    )\n",
    "\n",
    "    # worker dictionary\n",
    "    worker_dict = {}\n",
    "    worker_dict[\"center\"] = center\n",
    "    worker_dict[\"topo_c\"] = topo_c\n",
    "    worker_dict[\"im_c\"] = im_c\n",
    "    worker_dict[\"recon\"] = recon\n",
    "    worker_dict[\"factor\"] = factor\n",
    "    worker_dict[\"offset\"] = offset\n",
    "    worker_dict[\"shift\"] = shift\n",
    "    worker_dict[\"diff_c\"] = diff_c\n",
    "    worker_dict[\"sum_c\"] = sum_c\n",
    "    worker_dict[\"mask_bs\"] = mask_bs\n",
    "    worker_dict[\"mask_pixel\"] = mask_pixel\n",
    "\n",
    "    return worker_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b58f80-c8c8-4f69-a9dc-af85f590a7fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Setup phase and propagation for cdi once = np.array([1, 2, 3])\n",
    "\n",
    "# np.broadcast_to(x, (3, 3))\n",
    "phase_cdi = 0\n",
    "prop_dist_cdi = 0\n",
    "dx = 0\n",
    "dy = 0\n",
    "\n",
    "\n",
    "def phase_retrieval(\n",
    "    pos, neg, mask_pixel, supportmask, vmin=0, Startimage=None, Startgamma=None\n",
    "):\n",
    "    # Prepare Input holograms\n",
    "    pos2 = pos.copy()\n",
    "    neg2 = neg.copy()\n",
    "\n",
    "    mi, _ = np.percentile(pos2[pos2 != 0], [vmin, 99.9])\n",
    "    pos2 = pos2 - mi\n",
    "    mi, _ = np.percentile(neg2[neg2 != 0], [vmin, 99.9])\n",
    "    neg2 = neg2 - mi\n",
    "\n",
    "    pos2[pos2 < 0] = 0\n",
    "    neg2[neg2 < 0] = 0\n",
    "    pos2 = pos2.astype(complex)\n",
    "    neg2 = neg2.astype(complex)\n",
    "\n",
    "    bsmask_p = mask_pixel.copy()\n",
    "    bsmask_p[pos2 <= 0] = 1\n",
    "    bsmask_n = mask_pixel.copy()\n",
    "    bsmask_n[neg2 <= 0] = 1\n",
    "\n",
    "    # Setup start image and startgamma\n",
    "    if Startimage is None:\n",
    "        Startimage = np.fft.fftshift(np.fft.ifft2(np.fft.ifftshift(supportmask)))\n",
    "    else:\n",
    "        Startimage = Startimage.copy()\n",
    "    if Startgamma is None:\n",
    "        Startgamma = np.ones(pos.shape) * 1e-6 * 2\n",
    "        Startgamma[pos.shape[0] // 2, pos.shape[1] // 2] = 0.7\n",
    "    else:\n",
    "        Startgamma = Startgamma.copy()\n",
    "\n",
    "    # Settings for phase retrieval reconstructions\n",
    "    partial_coherence = True\n",
    "\n",
    "    # Setup\n",
    "    retrieved_p = np.zeros(pos2.shape, np.cdouble)\n",
    "    retrieved_n = np.zeros(pos2.shape, np.cdouble)\n",
    "\n",
    "    # Algorithms and Inital guess\n",
    "    plt.rcParams[\"figure.dpi\"] = 100\n",
    "    print(\"CDI - larger mask\")\n",
    "\n",
    "    algorithm_list = [\"mine\", \"mine\", \"mine\"]\n",
    "    Nit_list = [700, 50, 50]  # iterations for algorithm_list\n",
    "\n",
    "    x = (np.sqrt(np.maximum(pos2, np.zeros(pos2.shape)))[mask_pixel == 0]).flatten()\n",
    "    y = ((np.abs(Startimage))[mask_pixel == 0]).flatten()\n",
    "    res = stats.linregress(x, y)\n",
    "    Startimage -= res.intercept\n",
    "    Startimage /= res.slope\n",
    "\n",
    "    average_img = 30\n",
    "    real_object = False  # always set to False\n",
    "\n",
    "    if partial_coherence:\n",
    "        RL_freq = 20\n",
    "        RL_it = 50\n",
    "\n",
    "        algorithm_list_pc = [\"mine\", \"ER\", \"ER\"]\n",
    "        Nit_list_pc = [700, 50, 50]\n",
    "\n",
    "    # Execute Phase retrieval\n",
    "    start_time = time.time()\n",
    "    for i in range(len(Nit_list) // 3):\n",
    "        print(\"############ -   CDI\")\n",
    "\n",
    "        # Positive helicity - beta_mode=\"arctan\"\n",
    "        retrieved_p, Error_diff_p, Error_supp = PhR.PhaseRtrv_GPU(\n",
    "            diffract=np.sqrt(np.maximum(pos2, np.zeros(pos2.shape))),\n",
    "            mask=supportmask,\n",
    "            mode=algorithm_list[3 * i],\n",
    "            beta_zero=0.5,\n",
    "            Nit=Nit_list[3 * i],\n",
    "            beta_mode=\"arctan\",\n",
    "            plot_every=349,\n",
    "            Phase=Startimage,\n",
    "            seed=False,\n",
    "            real_object=real_object,\n",
    "            bsmask=bsmask_p,\n",
    "            average_img=average_img,\n",
    "            Fourier_last=True,\n",
    "        )\n",
    "\n",
    "        # Positive helicity - beta_mode=\"const\"\n",
    "        retrieved_p, Error_diff_p2, Error_supp = PhR.PhaseRtrv_GPU(\n",
    "            diffract=np.sqrt(np.maximum(pos2, np.zeros(pos2.shape))),\n",
    "            mask=supportmask,\n",
    "            mode=algorithm_list[3 * i + 1],\n",
    "            beta_zero=0.5,\n",
    "            Nit=Nit_list[3 * i + 1],\n",
    "            beta_mode=\"const\",\n",
    "            plot_every=24,\n",
    "            Phase=retrieved_p,\n",
    "            seed=False,\n",
    "            real_object=real_object,\n",
    "            bsmask=bsmask_p,\n",
    "            average_img=average_img,\n",
    "            Fourier_last=True,\n",
    "        )\n",
    "\n",
    "        # Negative helicity - beta_mode=\"arctan\"\n",
    "        retrieved_n, Error_diff_n2, Error_supp = PhR.PhaseRtrv_GPU(\n",
    "            diffract=np.sqrt(np.maximum(neg2, np.zeros(neg2.shape))),\n",
    "            mask=supportmask,\n",
    "            mode=algorithm_list[3 * i + 2],\n",
    "            beta_zero=0.5,\n",
    "            Nit=Nit_list[3 * i + 2],\n",
    "            beta_mode=\"const\",\n",
    "            plot_every=24,\n",
    "            Phase=retrieved_p * np.sqrt(np.sum(neg2) / np.sum(pos2)),\n",
    "            seed=False,\n",
    "            real_object=real_object,\n",
    "            bsmask=bsmask_n,\n",
    "            average_img=average_img,\n",
    "            Fourier_last=True,\n",
    "        )\n",
    "\n",
    "        print(\"--- %s seconds ---\" % np.round((time.time() - start_time), 2))\n",
    "\n",
    "        Startimage = retrieved_p.copy()\n",
    "\n",
    "        # Partial coherence phase retrieval\n",
    "        if partial_coherence:\n",
    "            # CDI_PC\n",
    "            print(\"############   -   CDI_pc\")\n",
    "            pos3 = (np.abs(retrieved_p) ** 2) * bsmask_p + np.maximum(\n",
    "                pos2, np.zeros(pos2.shape)\n",
    "            ) * (1 - bsmask_p)\n",
    "            neg3 = (np.abs(retrieved_n) ** 2) * bsmask_n + np.maximum(\n",
    "                neg2, np.zeros(neg2.shape)\n",
    "            ) * (1 - bsmask_n)\n",
    "\n",
    "            # retrieve pos image\n",
    "            (\n",
    "                retrieved_p_pc,\n",
    "                Error_diff_p_pc,\n",
    "                Error_supp,\n",
    "                gamma_p,\n",
    "            ) = PhR.PhaseRtrv_with_RL(\n",
    "                diffract=np.sqrt(pos3),\n",
    "                mask=supportmask,\n",
    "                mode=algorithm_list_pc[3 * i],\n",
    "                beta_zero=0.5,\n",
    "                Nit=Nit_list_pc[3 * i],\n",
    "                beta_mode=\"arctan\",\n",
    "                gamma=Startgamma,\n",
    "                RL_freq=RL_freq,\n",
    "                RL_it=RL_it,\n",
    "                plot_every=349,\n",
    "                Phase=Startimage,\n",
    "                seed=False,\n",
    "                real_object=False,\n",
    "                bsmask=np.zeros(bsmask_p.shape),\n",
    "                average_img=average_img,\n",
    "                Fourier_last=True,\n",
    "            )\n",
    "\n",
    "            (\n",
    "                retrieved_p_pc,\n",
    "                Error_diff_p_pc2,\n",
    "                Error_supp,\n",
    "                gamma_p,\n",
    "            ) = PhR.PhaseRtrv_with_RL(\n",
    "                diffract=np.sqrt(pos3),\n",
    "                mask=supportmask,\n",
    "                mode=algorithm_list[3 * i + 1],\n",
    "                beta_zero=0.5,\n",
    "                Nit=Nit_list_pc[3 * i + 1],\n",
    "                beta_mode=\"const\",\n",
    "                gamma=gamma_p,\n",
    "                RL_freq=RL_freq,\n",
    "                RL_it=RL_it,\n",
    "                plot_every=24,\n",
    "                Phase=retrieved_p_pc,\n",
    "                real_object=False,\n",
    "                bsmask=np.zeros(bsmask_p.shape),\n",
    "                average_img=average_img,\n",
    "                Fourier_last=True,\n",
    "            )\n",
    "            (\n",
    "                retrieved_n_pc,\n",
    "                Error_diff_n_pc2,\n",
    "                Error_supp,\n",
    "                gamma_n,\n",
    "            ) = PhR.PhaseRtrv_with_RL(\n",
    "                diffract=np.sqrt(neg3),\n",
    "                mask=supportmask,\n",
    "                mode=algorithm_list[3 * i + 2],\n",
    "                beta_zero=0.5,\n",
    "                Nit=Nit_list_pc[3 * i + 2],\n",
    "                beta_mode=\"const\",\n",
    "                gamma=gamma_p,\n",
    "                RL_freq=RL_freq,\n",
    "                RL_it=RL_it,\n",
    "                plot_every=24,\n",
    "                Phase=retrieved_p_pc * np.sqrt(np.sum(neg2) / np.sum(pos2)),\n",
    "                real_object=False,\n",
    "                bsmask=np.zeros(bsmask_n.shape),\n",
    "                average_img=average_img,\n",
    "                Fourier_last=True,\n",
    "            )\n",
    "\n",
    "            print(\"--- %s seconds ---\" % np.round((time.time() - start_time), 2))\n",
    "\n",
    "            Startimage = retrieved_p_pc.copy()\n",
    "            Startgamma = gamma_p.copy()\n",
    "\n",
    "    print(\"Phase Retrieval Done!\")\n",
    "\n",
    "    return (\n",
    "        retrieved_p,\n",
    "        retrieved_n,\n",
    "        retrieved_p_pc,\n",
    "        retrieved_n_pc,\n",
    "        bsmask_p,\n",
    "        bsmask_n,\n",
    "        gamma_p,\n",
    "        gamma_n,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899226cb-251e-4346-acc9-f21f57d8153b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def optimize_phase_contrast(recon, supportmask, method=\"contrast\", prefered_color=None):\n",
    "    \"\"\"\n",
    "    Automatically shifts contrast of phase retrieval reconstruction into real part\n",
    "\n",
    "    Parameter\n",
    "    =========\n",
    "    recon : complex array\n",
    "        FTH/CDI reconstruction plane (Patterson map)\n",
    "    supportmask : array\n",
    "        Supportmask of Patterson map for phase retrieval\n",
    "    method : string\n",
    "        Choose method for phase optimization (\"contrast\",\"minima\",\"maxima\")\n",
    "    prefered_color : string or None\n",
    "        Shift contrast such that color of domains with largest are is white (\"white\"),\n",
    "        black (\"black\") or non-specific (None)\n",
    "\n",
    "    Output\n",
    "    ======\n",
    "    recon_optimized: complex array\n",
    "        reconstruction with optimized contrast\n",
    "    optimized_phase: complex scalar\n",
    "        phase corresponding to optimized reconstruction\n",
    "    ======\n",
    "    author: ck 2023\n",
    "    \"\"\"\n",
    "\n",
    "    # filter references from supportmask\n",
    "    mask = supportmask.copy()\n",
    "    mask = mask.astype(bool)\n",
    "    mask = skimage.morphology.remove_small_objects(mask, min_size=200)\n",
    "    mask = mask.astype(float)\n",
    "\n",
    "    # Make object aperture smaller to minimize edge effects\n",
    "    footprint = skimage.morphology.disk(4)\n",
    "    mask = skimage.morphology.erosion(mask, footprint)\n",
    "\n",
    "    # Gaussian filter to remove high intensity peaks\n",
    "    reco = scipy.ndimage.gaussian_filter(recon, 1)\n",
    "\n",
    "    # Different functions for optimization\n",
    "    def contrast(phi, reco, tmask):\n",
    "        temp = np.imag(reco * np.exp(1j * phi)) * tmask\n",
    "        mi, ma = np.percentile(temp[temp != 0], [1, 99])\n",
    "        contrast = ma - mi\n",
    "        return contrast\n",
    "\n",
    "    def minima(phi, reco, tmask):\n",
    "        tmp = np.real(reco * np.exp(1j * phi)) * tmask\n",
    "        minima, maxima = np.percentile(tmp[tmp != 0], [0.01, 99])\n",
    "        return minima\n",
    "\n",
    "    def maxima(phi, reco, tmask):\n",
    "        tmp = np.real(reco * np.exp(1j * phi)) * tmask\n",
    "        minima, maxima = np.percentile(tmp[tmp != 0], [0.01, 99])\n",
    "        return maxima\n",
    "\n",
    "    # Choose optimization method\n",
    "    if method == \"minima\":\n",
    "        optimized_phase = scipy.optimize.fminbound(\n",
    "            minima, -np.pi, np.pi, args=(recon, mask), disp=False\n",
    "        ).astype(float)\n",
    "    elif method == \"contrast\":\n",
    "        optimized_phase = scipy.optimize.fminbound(\n",
    "            contrast, -np.pi, np.pi, args=(recon, mask), disp=False\n",
    "        ).astype(float)\n",
    "    elif method == \"max\":\n",
    "        optimized_phase = scipy.optimize.fminbound(\n",
    "            contrast, -np.pi, np.pi, args=(recon, mask), disp=False\n",
    "        ).astype(float)\n",
    "\n",
    "    # Calc optimized reconstruction\n",
    "    recon_optimized = recon * np.exp(1j * optimized_phase)\n",
    "\n",
    "    # Optional: Shift phase such that \"background\" are white or black\n",
    "    mi_p, ma_p = np.percentile(np.real(recon_optimized[mask == 1]), [1, 99])\n",
    "    mean = np.mean(np.real(recon_optimized[mask == 1]))\n",
    "    if prefered_color == \"white\":\n",
    "        # Make white domains the dominant domains\n",
    "        if mean < (mi_p + ma_p) / 2:\n",
    "            optimized_phase = optimized_phase + np.pi\n",
    "            recon_optimized = recon * np.exp(1j * optimized_phase)\n",
    "    elif prefered_color == \"black\":\n",
    "        # Make black domains the dominant domains\n",
    "        if mean > (mi_p + ma_p) / 2:\n",
    "            optimized_phase = optimized_phase + np.pi\n",
    "            recon_optimized = recon * np.exp(1j * optimized_phase)\n",
    "\n",
    "    return recon_optimized, optimized_phase"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a18703-7ac3-4731-b0e6-6c3bcc6a8170",
   "metadata": {},
   "source": [
    "# Experimental Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3239b4-0a4f-466d-8bb3-a12e5bf02202",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Dict with most basic experimental parameter\n",
    "experimental_setup = {\n",
    "    \"ccd_dist\": 0.15,  # ccd to sample distance\n",
    "    \"px_size\": 6.5e-6,  # pixel_size of camera\n",
    "    \"binning\": 1,  # Camera binning\n",
    "    \"energy\": 778,  # photon energy\n",
    "    \"int_cutoff\": 40e3,  # Camera saturation threshold\n",
    "}\n",
    "experimental_setup[\"lambda\"] = cci.photon_energy_wavelength(\n",
    "    experimental_setup[\"energy\"], input_unit=\"eV\"\n",
    ")\n",
    "\n",
    "# Setup for azimuthal integrator\n",
    "detector = Detector(\n",
    "    experimental_setup[\"binning\"] * experimental_setup[\"px_size\"],\n",
    "    experimental_setup[\"binning\"] * experimental_setup[\"px_size\"],\n",
    ")\n",
    "\n",
    "# General saving folder and log folder\n",
    "folder_target = sup.create_folder(join(BASEFOLDER, \"work\", \"Analysis\"))\n",
    "sup.create_folder(join(folder_target, \"Logs\"))\n",
    "sup.create_folder(join(folder_target, \"Topos\"))\n",
    "print(\"Output Folder: %s\" % folder_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a96b504d-6ee3-497d-917a-2e8f345c352a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Load images\n",
    "\n",
    "Start by loading the images: image of interest (im), reference of charge scattering (topo), any kind of dark image (dark)\n",
    "\n",
    "We estalished the following convention: Difference Hologram which contains only the magnetic scattering will be calculated according to:\n",
    "\n",
    "$Diff = \\frac{Image}{factor} - Topo$,\n",
    "\n",
    "where the factor is used for intensity scaling. In Case that you recorded scans of the same magnetic state with both helicities, use the image with negative helicity as topo and the one with positive helicity as image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4df9df-22f6-4b14-8edd-2f9500b63f83",
   "metadata": {},
   "source": [
    "### Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0bc8ab-6b64-4535-8e03-fcca338f5ee9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define ids of different run numbers for image loading\n",
    "im_id = 223  # single helicity mode: image with magnetic contrast, double helicity: pos\n",
    "topo_id = (\n",
    "    221  # single helicity mode: image without magnetic contrast, double helicity: neg\n",
    ")\n",
    "dark_id = 222  # camera background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e525ef-c3a9-4e60-8809-e9f8ac6ba5f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ids = list_acquisition_filenames(im_id, acq_nrs=[], ONLY_CAMERA=True)\n",
    "image, _ = load_processing_frames(ids, loadmode=\"avg\", crop=0)\n",
    "\n",
    "# Plot\n",
    "fig, ax = cimshow(image)\n",
    "ax.set_title(\"Image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "595101ee-2a0f-4fec-aeb8-506e781eaf99",
   "metadata": {},
   "source": [
    "## Load topo data set and average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82168cb5-c3cb-4ca5-8716-75870eb438a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ids = list_acquisition_filenames(topo_id, acq_nrs=[], ONLY_CAMERA=True)\n",
    "topo, _ = load_processing_frames(ids, loadmode=\"avg\", crop=0)\n",
    "\n",
    "# Plot\n",
    "fig, ax = cimshow(topo)\n",
    "ax.set_title(\"Topo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab31810-3451-442d-a682-644b86fddf0c",
   "metadata": {},
   "source": [
    "## Load dark image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9f0287-8920-43f4-a936-a157d9e8c02f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load image\n",
    "if dark_id is not None:\n",
    "    ids = list_acquisition_filenames(dark_id, acq_nrs=[], ONLY_CAMERA=True)\n",
    "    dark, _ = load_processing_frames(\n",
    "        ids,\n",
    "        crop=0,\n",
    "    )\n",
    "\n",
    "    # Plot\n",
    "    fig, ax = cimshow(dark)\n",
    "    ax.set_title(\"Dark\")\n",
    "    \n",
    "# Subtract dark images\n",
    "image = image - dark\n",
    "topo = topo - dark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24416119-e31f-42de-b71a-2c557250acb2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Thresholding to prevent negative values\n",
    "topo[topo < 1] = 0\n",
    "image[image < 1] = 0\n",
    "\n",
    "fig, ax = cimshow(image)\n",
    "ax.set_title(\"Image with subtracted dark\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5dcb22e-86c3-4b31-83f9-db926e9ed269",
   "metadata": {},
   "source": [
    "# Center holograms\n",
    "\n",
    "* Find center of the hologram to get a well-defined q-space. \n",
    "* Create smooth mask for beamstop or overexposed areas in direct beam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2a0e76-1176-48bb-a519-ffef61461bdd",
   "metadata": {},
   "source": [
    "## Basic widget to find center\n",
    "\n",
    "Try to **align** the circles to the **center of the scattering pattern**. Care! Position of beamstop might be misleading and not represent the actual center of the hologram. Circles are just a guide to eye and will not be used otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f94108-cea7-47b9-a686-1d05146134e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Find center position via widget\n",
    "c0, c1 = [1037, 1006]  # initial values\n",
    "ic = interactive.InteractiveCenter(image, c0=c0, c1=c1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591d37a7-af5a-4a13-b312-2818a3a3b750",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get center positions\n",
    "center = [ic.c0, ic.c1]\n",
    "print(f\"Center:\", center)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bbcb3e2-e57d-4f19-a76a-b616d824a6fd",
   "metadata": {},
   "source": [
    "## Azimuthal integrator widget for finetuning\n",
    "More of an \"expert widget\" which works very well for alignment if you have an Airy Pattern as a scattering image. PyFai transforms images from carthesian detector coordinate system into polar coordinate system with angle `phi` and radial distance `q` as axis (azimuthal transformation). The center of the coordinate system will be defined in the azimuthal integrator class and must not necessarily represents the center coordinates of your image array. If the center is set correctly, all rings of the Airy pattern will be transformed into a straight line in the I(q,chi)-plot as rings appear at a given q for all angles chi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac6dcf7-5779-48d6-b5f9-9e9433d3b875",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Setup azimuthal integrator for virtual geometry\n",
    "ai = AzimuthalIntegrator(\n",
    "    dist=experimental_setup[\"ccd_dist\"],\n",
    "    detector=detector,\n",
    "    wavelength=experimental_setup[\"lambda\"],\n",
    "    poni1=center[0]\n",
    "    * experimental_setup[\"px_size\"]\n",
    "    * experimental_setup[\"binning\"],  # y (vertical)\n",
    "    poni2=center[1]\n",
    "    * experimental_setup[\"px_size\"]\n",
    "    * experimental_setup[\"binning\"],  # x (horizontal)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a692999-cc96-44d9-ab4a-9659b270280f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Not the widget, just for double checking to find correct radial range for plotting\n",
    "# Perform azimuthal transformation\n",
    "I_t, q_t, phi_t = ai.integrate2d(\n",
    "    np.log10(image - np.min(image) + 1),\n",
    "    500,  # number of points for phi\n",
    "    radial_range=(0.01, 0.1),  # relevant q-range\n",
    "    unit=\"q_nm^-1\",\n",
    "    correctSolidAngle=False,\n",
    "    method=\"BBox\",\n",
    ")\n",
    "# Combine in an xarray for plotting\n",
    "az2d = xr.DataArray(I_t, dims=(\"phi\", \"q\"), coords={\"q\": q_t, \"phi\": phi_t})\n",
    "\n",
    "# Plot\n",
    "fig, ax = plt.subplots()\n",
    "mi, ma = np.percentile(I_t, [1, 95])\n",
    "az2d.plot.imshow(ax=ax, vmin=mi, vmax=ma)\n",
    "plt.title(f\"Azimuthal integration\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b2ccb3-b117-48d0-8883-2b393de08d01",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The widget\n",
    "aic = interactive.AzimuthalIntegrationCenter(\n",
    "    np.log10(image - np.min(image) + 1),\n",
    "    # image,\n",
    "    ai,\n",
    "    c0=center[0],\n",
    "    c1=center[1],\n",
    "    im_data_range=[1, 98],\n",
    "    radial_range=(0.01, 0.05),\n",
    "    qlines=[100, 110],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8093bc30-bc45-42c0-83bc-16e105ffce86",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get center positions from widget\n",
    "center = [aic.c0, aic.c1]\n",
    "print(f\"Center:\", center)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3abf468c-3c47-4aeb-b2c8-4f828653304c",
   "metadata": {},
   "source": [
    "## Centering of image hologram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3970edfd-7665-4c17-83e9-53354419f165",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Shift origin q0 to center of array\n",
    "shift_c = np.array(image.shape) / 2 - center\n",
    "im_c = cci.shift_image(image, shift_c)\n",
    "topo_c = cci.shift_image(topo, shift_c)  # centered image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e48b7bdd-fc81-4ca3-8ad1-ed827fb9dd2a",
   "metadata": {},
   "source": [
    "# Image Registration\n",
    "\n",
    "Relative drift between data holograms and their corresponding topo holograms is calculated by image registration algorithm. Necessary to get well defined difference hologram. The reference is always the static background image (topo)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38014a4a-0140-4175-bb8f-28dbc791e4b4",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Set Alignment ROI \n",
    "\n",
    "Set a region of interest (ROI) of reference (topo) use for image registration is performed. Can include beamstop when beamstop mask was defined.\n",
    "\n",
    "How to use:\n",
    "1. Zoom into the image and adjust your FOV until you are satisfied.\n",
    "2. Save the axes coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb6bd7e-6e2d-461c-a676-2b621b85cdc6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = cimshow(im_c)\n",
    "ax.set_title(\"Don't include the beamstop as this will misdirect the algorithm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e7cbe8-bd84-4d67-8620-a568768c63cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Takes start and end of x and y axis\n",
    "x1, x2 = ax.get_xlim()\n",
    "y2, y1 = ax.get_ylim()\n",
    "roi_im_reg = np.array([y1, y2, x1, x2]).astype(int)\n",
    "roi_im_reg = [508, 970, 1052, 1650]\n",
    "roi_im_reg_s = np.s_[roi_im_reg[0] : roi_im_reg[1], roi_im_reg[2] : roi_im_reg[3]]\n",
    "\n",
    "print(f\"Image registration roi:\", roi_im_reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4f25c09-5280-451a-8f26-a2c87375ac1c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Calculate drift of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0fea74-3ec7-4779-be9c-6fc83102b4cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "shift = cci.image_registration(\n",
    "    im_c[roi_im_reg_s],\n",
    "    topo_c[roi_im_reg_s],\n",
    "    method=\"dipy\",\n",
    ")\n",
    "print(\"Relative shift is: %s\" % shift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b31c16f-6b3a-43d0-a952-c758ad45d8b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define shift manually for comparison\n",
    "tmp_shift = [0.03, 20]\n",
    "\n",
    "# Loop over shifts\n",
    "temp_diff = np.zeros((3, im_c.shape[0], im_c.shape[1]))\n",
    "shifts = [\n",
    "    [0, 0],\n",
    "    tmp_shift,\n",
    "    -shift,\n",
    "]\n",
    "for i, tshift in enumerate(shifts):\n",
    "    temp = cci.shift_image(im_c, tshift)\n",
    "    temp_factor = cci.dyn_factor(temp, topo_c)\n",
    "    temp_diff[i] = temp - temp_factor[0] * topo_c\n",
    "\n",
    "# Plots for comparision\n",
    "fig, ax = plt.subplots(1, 3, sharex=True, sharey=True, figsize=(12, 4))\n",
    "mi, ma = np.percentile(temp_diff[0], [0.1, 99.9])\n",
    "ax[0].imshow(temp_diff[0], vmin=mi, vmax=ma)\n",
    "ax[0].set_title(\"Zero shift\")\n",
    "mi, ma = np.percentile(temp_diff[1], [0.1, 99.9])\n",
    "ax[1].imshow(temp_diff[1], vmin=mi, vmax=ma)\n",
    "ax[1].set_title(\"Manual shift: %s\" % shifts[1])\n",
    "mi, ma = np.percentile(temp_diff[2], [0.1, 99.9])\n",
    "ax[2].imshow(temp_diff[2], vmin=mi, vmax=ma)\n",
    "ax[2].set_title(\"Auto shift: %s\" % np.round(shifts[2], 2))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ca877e59-98ef-4b45-b069-52cf0fd58a52",
   "metadata": {
    "tags": []
   },
   "source": [
    "# If the shift is very small you might want to set it to [0,0]\n",
    "shift = [0, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20df6475-fed2-40f4-986e-5cef36424196",
   "metadata": {},
   "source": [
    "## Correct drift of topo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79005401-e5a5-4469-b91e-e3fbd6f38016",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Correct relative drift image and topo\n",
    "topo_c = cci.shift_image(topo_c, shift)\n",
    "\n",
    "# Plot original and shifted holos\n",
    "mi, ma = np.percentile(np.real(im_c[im_c != 0]), (0.1, 99))\n",
    "fig, ax = plt.subplots(1, 2, sharex=True, sharey=True, figsize=(8, 4))\n",
    "ax[0].imshow(np.real(topo), cmap=\"viridis\", vmin=mi, vmax=ma)\n",
    "ax[0].set_title(\"Uncentered topo\")\n",
    "ax[1].imshow(np.real(topo_c), cmap=\"viridis\", vmin=mi, vmax=ma)\n",
    "ax[1].set_title(\"Centered topo with beamstop\")\n",
    "\n",
    "# Add circles with different radi r\n",
    "tmp = np.array(image.shape) / 2\n",
    "for r in np.arange(50, 200, 25):\n",
    "    ax[0].add_artist(plt.Circle((tmp[1], tmp[0]), r, fill=None, ec=\"red\"))\n",
    "    ax[1].add_artist(plt.Circle((tmp[1], tmp[0]), r, fill=None, ec=\"red\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d79195f-489c-4fdb-999d-ba1eee53b4ff",
   "metadata": {},
   "source": [
    "# Create beamstops\n",
    "\n",
    "We want to cover the beamstop with a smooth circle to cover its sharp edges as these would create ringing-like artifacts in the reconstruction plane. Make it only as large as necessary to keep as much information as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d744d4cb-6f50-4ab6-8f13-8fb0fc29347a",
   "metadata": {},
   "source": [
    "## Circle beamstop\n",
    "\n",
    "Set beamstop diameter and std for smoothing filter. Higher values mean stronger smoothing. If you have a very small beamstop you might need to reduce the smoothing value. Otherwise the sharp gradient of the real beamstop will still be visible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a2acd8-69d5-4873-9771-0fcf7e9d5db7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bs = interactive.InteractiveBeamstop(im_c, 1019, 1023, rBS=51, stdBS=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191ab9b8-7792-41e0-8312-996fc74c369c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Take value from widget and create beamstop mask\n",
    "mask_bs = 1 - mask_lib.circle_mask(topo.shape, bs.center, bs.rBS, sigma=bs.stdBS)\n",
    "\n",
    "# Apply beamstop to image\n",
    "im_b = im_c * mask_bs\n",
    "\n",
    "# Plot image with beamstop and valid pixel mask\n",
    "fig, ax = plt.subplots(1, 3, sharex=True, sharey=True, figsize=(9, 3))\n",
    "mi, ma = np.percentile(im_b, [0.1, 99.9])\n",
    "ax[0].imshow(im_b, cmap=\"viridis\", vmin=mi, vmax=ma)\n",
    "ax[0].set_title(\"Masked image\")\n",
    "\n",
    "ax[1].imshow(mask_bs)\n",
    "ax[1].set_title(\"Beamstop mask\")\n",
    "\n",
    "ax[2].imshow(1 - mask_bs)\n",
    "ax[2].set_title(\"1 - Beamstop mask\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a36fadd-9679-4f62-bd63-23099e130dfd",
   "metadata": {},
   "source": [
    "## Manual masking of beamstop wires\n",
    "\n",
    "Just mask the beamstop wires, broken pixels, etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356f7a0f-00c0-4f84-b716-fbe27cf1af40",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "poly_mask = interactive.draw_polygon_mask(im_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676beb04-e083-40e7-9914-cd7b968cc792",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Take poly coordinates and mask from widget\n",
    "p_coord = poly_mask.get_vertice_coordinates()\n",
    "mask_draw = poly_mask.full_mask.astype(int)\n",
    "\n",
    "print(\"Copy these coordinates into the 'load_poly_coordinates()' function:\")\n",
    "print(p_coord)\n",
    "\n",
    "# Plot image with beamstop and valid pixel mask\n",
    "fig, ax = plt.subplots(1, 3, sharex=True, sharey=True, figsize=(9, 3))\n",
    "mi, ma = np.percentile(im_c * (1 - mask_draw), [0.1, 99.9])\n",
    "ax[0].imshow(im_c * (1 - mask_draw), cmap=\"viridis\", vmin=mi, vmax=ma)\n",
    "ax[0].set_title(\"Image * (1-mask_draw)\")\n",
    "\n",
    "mi, ma = np.percentile(im_c * mask_draw, [0.1, 99.9])\n",
    "ax[1].imshow(im_c * mask_draw, vmin=mi, vmax=ma)\n",
    "ax[1].set_title(\"Image * mask_draw\")\n",
    "\n",
    "ax[2].imshow(1 - mask_draw)\n",
    "ax[2].set_title(\"1 - mask_draw\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e867740c-6422-4e13-b754-826e04f0fdce",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_poly_coordinates():\n",
    "    \"\"\"\n",
    "    Dictionary that stores polygon corner coordinates of all drawn masks\n",
    "    Example: How to add masks with name \"test\":\n",
    "    mask_coordinates[\"test\"] = copy coordinates from above\n",
    "    \"\"\"\n",
    "\n",
    "    # Setup dictonary\n",
    "    mask_coordinates = dict()\n",
    "\n",
    "    # Mask #1\n",
    "    mask_coordinates[\"bs_cross\"] = [\n",
    "        [\n",
    "            (236.2 - 8, 47.0 - 49),\n",
    "            (403.7 - 8, 225.8 - 4),\n",
    "            (729.4 - 8, 635.1 - 4),\n",
    "            (877.8 - 8, 827.5 - 4),\n",
    "            (1001.0 - 8, 997.3 - 4),\n",
    "            (999.7 - 8, 1021.3 - 4),\n",
    "            (995.0 - 8, 1049.8 - 4),\n",
    "            (704.0 - 8, 1387.5 - 4),\n",
    "            (176.9 - 8, 1947.6 - 4),\n",
    "            (204.3 - 8, 1947.6 - 4),\n",
    "            (640.8 - 8, 1486.3 - 4),\n",
    "            (783.3 - 8, 1318.9 - 4),\n",
    "            (1006.2 - 8, 1052.5 - 4),\n",
    "            (1041.7 - 8, 1047.1 - 4),\n",
    "            (1066.0 - 8, 1027.5 - 4),\n",
    "            (2023.7 - 8, 1075.3 - 4),\n",
    "            (2021.7 - 8, 1049.8 - 4),\n",
    "            (1067.8 - 8, 1016.0 - 4),\n",
    "            (1016.6 - 8, 988.9 - 4),\n",
    "            (894.1 - 8, 824.2 - 4),\n",
    "            (764.0 - 8, 644.5 - 4),\n",
    "            (482.3 - 8, 261.0 - 4),\n",
    "            (281.2 - 8, 14.8 - 4),\n",
    "        ]\n",
    "    ]\n",
    "    mask_coordinates[\"Some_Wire\"] = [\n",
    "        [\n",
    "            (808.9 + 97, -20.4 + 100),\n",
    "            (944.0 + 97, 269.1 + 100),\n",
    "            (1233.0 + 97, 826.6 + 100),\n",
    "            (1537.1 + 97, 1457.0 + 100),\n",
    "            (1666.3 + 97, 1689.8 + 100),\n",
    "            (1822.7 + 97, 1997.1 + 100),\n",
    "            (2127.0 + 97, 1769.1 + 100),\n",
    "            (2067.6 + 97, 1544.6 + 100),\n",
    "            (1575.5 + 97, 555.6 + 100),\n",
    "            (1273.5 + 97, -28.9 + 100),\n",
    "        ]\n",
    "    ]\n",
    "    mask_coordinates[\"membrane_slit\"] = [\n",
    "        [\n",
    "            (1037.0 + 0.5 - 4.5, 899.5 + 100 + 4.5),\n",
    "            (1022.4 + 0.5 - 4.5, 899.3 + 100 + 4.5),\n",
    "            (1020.8 + 0.5 - 4.5, 982.7 + 100 + 4.5),\n",
    "            (1032.3 + 0.5 - 4.5, 983.0 + 100 + 4.5),\n",
    "            (1035.6 + 0.5 - 4.5, 940.5 + 100 + 4.5),\n",
    "        ]\n",
    "    ]\n",
    "    mask_coordinates[\"wire_new\"] = [[(1569.0, -17.5), (2083.9, 995.9), (2075.7, -34.0)]]\n",
    "    return mask_coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5109b8ab-3f5b-415c-99a8-057dab26711a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Which drawn masks do you want to load? You can combine multiple masks from\n",
    "# load_poly_coordinates(). Just add names of mask as strings to list like\n",
    "# [\"bs_small\",\"bs_medium\"]\n",
    "polygon_names = [\"bs_cross\"]  # [\"bs_test\"]\n",
    "mask_draw = mask_lib.load_poly_masks(\n",
    "    im_c.shape,\n",
    "    load_poly_coordinates(),\n",
    "    polygon_names,\n",
    ")\n",
    "\n",
    "# Expand/shrink Mask if necessary\n",
    "# footprint = skimage.morphology.disk(3)\n",
    "# mask_draw = skimage.morphology.dilation(mask_draw, footprint) # increase size\n",
    "# mask_draw = skimage.morphology.erosion(mask_draw, footprint) # decrease size\n",
    "\n",
    "# The relative position of the drawn beamstop with respect to the actual beamstop\n",
    "# might change due to sample change, sample drift, realignment, etc. The drawn\n",
    "# beamstop mask would therefore not cover the actual beamstop position. This function\n",
    "# aligns the beamstop mask with respect to the actual position\n",
    "optimize_position = True\n",
    "\n",
    "# Optimize position of drawn mask relative to target image\n",
    "if optimize_position is True:\n",
    "    # level 1 (rough)\n",
    "    optimized_shift, mask_shifted, _ = mask_lib.auto_shift_mask(\n",
    "        mask_draw,\n",
    "        im_c,\n",
    "        shift_range_y=[-10, 10],\n",
    "        shift_range_x=[-10, 10],\n",
    "        step_size=4,\n",
    "        crop=300,\n",
    "    )\n",
    "    ## Level 2 (fine)\n",
    "    optimized_shift, mask_shifted, overlap = mask_lib.auto_shift_mask(\n",
    "        mask_draw,\n",
    "        im_c,\n",
    "        shift_range_y=[optimized_shift[0] - 4, optimized_shift[0] + 4],\n",
    "        shift_range_x=[optimized_shift[1] - 4, optimized_shift[1] + 4],\n",
    "        step_size=0.5,\n",
    "        crop=300,\n",
    "    )\n",
    "    mask_draw = mask_shifted.copy()\n",
    "\n",
    "# Shift mask\n",
    "# mask_draw = np.round(cci.shift_image(mask_draw,[2,0]))\n",
    "\n",
    "# Plot image with beamstop and valid pixel mask\n",
    "fig, ax = plt.subplots(1, 3, sharex=True, sharey=True, figsize=(9, 3))\n",
    "mi, ma = np.percentile(im_c * (1 - mask_draw), [0.1, 99])\n",
    "ax[0].imshow(im_c * (1 - mask_draw), cmap=\"viridis\", vmin=mi, vmax=ma)\n",
    "ax[0].set_title(\"Image * (1-mask_draw)\")\n",
    "\n",
    "# mi, ma = np.percentile(im_c * mask_draw, [0.1, 90])\n",
    "ax[1].imshow(im_c * mask_draw, vmin=mi, vmax=ma)\n",
    "ax[1].set_title(\"Image * mask_draw\")\n",
    "\n",
    "ax[2].imshow(1 - mask_draw)\n",
    "ax[2].set_title(\"1 - mask_draw\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21a8ab9-8700-4965-9efc-f5c9cd42e8b7",
   "metadata": {},
   "source": [
    "## Finetuning of mask position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da146b89-b5b6-45f9-9c48-4ccdd738c23d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Use widget to shift and expand or shrink the mask\n",
    "ss_mask = interactive.Shift_Scale_Mask(im_c, mask_draw, shift=[0, 0], scale=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ce4158-8566-4d8b-b8f7-4bdd8ed197e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Take mask, shift and scaling from widget\n",
    "mask_draw, mask_shift, mask_scale = ss_mask.get_mask()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429dff9e-b21e-490a-83ef-396a94a15896",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Add circular beamstop mask\n",
    "mask_im = mask_draw.copy()\n",
    "mask_topo = mask_im.copy()\n",
    "\n",
    "# Mask over-saturated pixel\n",
    "mask_im = mask_im + (im_c > experimental_setup[\"int_cutoff\"])\n",
    "mask_topo = mask_topo + (topo_c > experimental_setup[\"int_cutoff\"])\n",
    "\n",
    "# Combine both\n",
    "mask_pixel = mask_im + mask_topo\n",
    "mask_pixel[mask_pixel > 1] = 1\n",
    "\n",
    "# Create smooth mask for FTH reconstructions\n",
    "footprint = skimage.morphology.disk(6)\n",
    "mask_pixel_smooth = skimage.morphology.dilation(mask_pixel, footprint)\n",
    "mask_pixel_smooth = gaussian_filter(mask_pixel_smooth, 2)\n",
    "\n",
    "# Plot both\n",
    "fig, ax = plt.subplots(2, 4, figsize=(10, 5), sharex=True, sharey=True)\n",
    "mi, ma = np.percentile(im_c, [1, 99.9])\n",
    "ax[0, 0].imshow(im_c, vmin=mi, vmax=ma)\n",
    "ax[0, 0].set_title(\"Image\")\n",
    "mi, ma = np.percentile(im_c * mask_im, [1, 99.99])\n",
    "ax[0, 1].imshow(im_c * mask_im, vmin=mi, vmax=ma)\n",
    "ax[0, 1].set_title(\"Image*mask\")\n",
    "mi, ma = np.percentile(im_c * (1 - mask_im), [0.1, 99.9])\n",
    "ax[0, 2].imshow(im_c * (1 - mask_im), vmin=mi, vmax=ma)\n",
    "ax[0, 2].set_title(\"Image*(1-mask)\")\n",
    "ax[0, 3].imshow(mask_pixel_smooth)\n",
    "ax[0, 3].set_title(\"Combined Mask\")\n",
    "\n",
    "mi, ma = np.percentile(topo_c, [1, 99.9])\n",
    "ax[1, 0].imshow(topo_c, vmin=mi, vmax=ma)\n",
    "ax[1, 0].set_title(\"Topo\")\n",
    "mi, ma = np.percentile(topo_c * mask_im, [1, 99.99])\n",
    "ax[1, 1].imshow(topo_c * mask_topo, vmin=mi, vmax=ma)\n",
    "ax[1, 1].set_title(\"Topo*mask\")\n",
    "mi, ma = np.percentile(topo_c * (1 - mask_topo), [0.1, 99.9])\n",
    "ax[1, 2].imshow(topo_c * (1 - mask_topo), vmin=mi, vmax=ma)\n",
    "ax[1, 2].set_title(\"topo*(1-mask)\")\n",
    "mi, ma = np.percentile((im_c - topo_c) * (1 - mask_pixel_smooth), [0.1, 99.9])\n",
    "ax[1, 3].imshow((im_c - topo_c) * (1 - mask_pixel_smooth), vmin=mi, vmax=ma)\n",
    "ax[1, 3].set_title(\"Image-Topo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ac77ba-6eaf-4d33-a306-72a80fe0a77e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Calculate difference holograms\n",
    "\n",
    "You can see the reconstrution of the magnetization only after subtracting the large background that you get from the diffraction on the circular object aperture (Airy Pattern). This might require a scaling factor to correct intensity changes between the hologram and the topo. Scaling factor will be determined automatically by a linear fit. If the fit seems off, there might be an issue with the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d8b5325-3ff3-4f19-9ee5-badff4287d51",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get scaling factor and offset\n",
    "factor, offset = cci.dyn_factor(\n",
    "    im_c * (1 - mask_pixel),\n",
    "    topo_c * (1 - mask_pixel),\n",
    "    method=\"correlation\",\n",
    "    print_out=True,\n",
    "    plot=True,\n",
    ")\n",
    "\n",
    "# Calculate differences (magnetic) and sums (topographc) contrast holograms.\n",
    "# _c: centered, without beamstop, _b: centered, with beamstop\n",
    "diff_c = im_c / factor - topo_c - offset\n",
    "diff_b = diff_c * mask_bs\n",
    "sum_c = im_c / factor + topo_c - offset\n",
    "sum_b = sum_c * mask_bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ff2a30-8cd0-4dc9-9d0e-f013329eff5b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Plot an example of the difference or sum hologram\n",
    "fig, ax = cimshow(diff_c * (1 - mask_pixel_smooth))\n",
    "ax.set_title(f\" Diff Id %s - %s\" % (im_id, topo_id))\n",
    "\n",
    "# fig, ax = cimshow(sum_b)\n",
    "# ax.set_title(f\" Sum Id %d\" % im_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b0661f7-4bc2-4c58-82f4-4b3deb612627",
   "metadata": {},
   "source": [
    "# Reconstruct Diff Holos (FTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b60771-c80a-4b8a-8cb6-df71bf58509f",
   "metadata": {
    "tags": []
   },
   "source": [
    "0. If you are doing heraldo, determine the rotation angle of the hologram\n",
    "1. Choose a region of interest (ROI) which means selecting one reconstruction from the reconstruction plane.\n",
    "2. Propagate the image and shift the phase for maximal contrast and sharpness in your ROI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a68a4b79-c83d-407d-aaa4-50a138ff1899",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Set Patterson Map ROI\n",
    "\n",
    "Choose the reconstructions as the ROI.\n",
    "\n",
    "1. Zoom into the image and adjust your FOV until you are satisfied.\n",
    "2. Save the axes coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587a433d-d021-495e-a5bb-eec9b7f8edc5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Choose contrast mode\n",
    "# diff_c: magnetic contrast only\n",
    "# sum_c: topographic contrast only\n",
    "\n",
    "holo = diff_c * mask_bs * (1 - mask_pixel_smooth)\n",
    "# holo = sum_c * mask_bs * (1 - mask_pixel_smooth)\n",
    "# holo = im_c * mask_bs * (1 - mask_pixel_smooth)\n",
    "# holo = topo_c * mask_bs * (1 - mask_pixel_smooth)\n",
    "\n",
    "fig, ax = cimshow(np.real(fth.reconstruct(holo)), cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b35ce43-1372-44d6-bc4c-9684883bacbb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Execute to get roi\n",
    "x1, x2 = ax.get_xlim()\n",
    "y2, y1 = ax.get_ylim()\n",
    "roi = np.array([y1, y2, x1, x2]).astype(int)  # ystart, ystop, xstart, xstop\n",
    "roi = [811, 906, 902, 1003]\n",
    "roi_s = np.s_[roi[0] : roi[1], roi[2] : roi[3]]\n",
    "print(f\"Roi Reco:{roi}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2286df01-deba-4220-81f8-e467df49e563",
   "metadata": {},
   "source": [
    "## Tune propagation and phase\n",
    "Focus the image by tuning the propagation distance. This really works like focussing in a microscope.\n",
    "Phase slider will move contrast between real and imaginary part. Usually we use the phase which maximizes the contrast in the real part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9992951e-929b-4d47-a716-19a53e45c0bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Widget\n",
    "slider_prop, slider_phase, button = reco.propagate(\n",
    "    holo,\n",
    "    roi_s,\n",
    "    phase=1.5,  # Initial value\n",
    "    prop_dist=2.1,  # Initial value\n",
    "    experimental_setup=experimental_setup,\n",
    "    scale=(0.1, 99.9),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627c0d1a-4541-430e-8553-b0f60aa6bd52",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Read prop dist and phase from widget\n",
    "prop_dist = slider_prop.value\n",
    "phase = slider_phase.value\n",
    "\n",
    "print(f\"Propagation distance: %0.2f\" % prop_dist)\n",
    "print(f\"Phase: %0.2f\" % phase)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6865613a-d8fe-46e8-abb7-f7cab1f02a3b",
   "metadata": {},
   "source": [
    "## Save reconstruction\n",
    "\n",
    "Save png files of the images and a h5 file containing all important variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117cf931-b70f-4263-94cf-61941ef9b64e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Style of reconstruction plot\n",
    "def plot_recon(recon, title):\n",
    "    # Plot\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(10, 4))\n",
    "    fig.suptitle(title)\n",
    "\n",
    "    vmin, vmax = np.percentile(np.real(recon), (1, 99))\n",
    "    t_im1 = ax[0].imshow(np.real(recon), vmin=vmin, vmax=vmax, cmap=\"gray\")\n",
    "    ax[0].set_title(\"Real\")\n",
    "    # plt.colorbar(t_im1, ax=ax[0], aspect=50)\n",
    "\n",
    "    vmin, vmax = np.percentile(np.imag(recon), (1, 99))\n",
    "    t_im2 = ax[1].imshow(np.imag(recon), vmin=vmin, vmax=vmax, cmap=\"gray\")\n",
    "    ax[1].set_title(\"Imag\")\n",
    "    # plt.colorbar(t_im2, ax=ax[1], aspect=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6558f92b-5884-46c8-a4be-a904761b791f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_title(data_key, im_id, topo_id, CDI=False):\n",
    "    # Rotation in title\n",
    "    # values = np.mean(np.array(load_pre_scan_snapshot(im_id, data_key)) * 1000)\n",
    "    # values = [np.round(values, 2)]\n",
    "\n",
    "    # Rotation in title\n",
    "    # values = load_pre_scan_snapshot(im_id, data_key)\n",
    "\n",
    "    if CDI is False:\n",
    "        mode = \"FTH\"\n",
    "    elif CDI is True:\n",
    "        mode = \"CDI\"\n",
    "\n",
    "    if data_key == None:\n",
    "        title = \"%s: %s - %s\" % (mode, im_id, topo_id)\n",
    "\n",
    "    return title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d292ede3-558f-47e3-9518-82ea8e55aa03",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create plot\n",
    "holo = diff_c * mask_bs * (1 - mask_pixel_smooth)\n",
    "\n",
    "# Reconstruct\n",
    "recon = fth.reconstruct(\n",
    "    fth.propagate(holo, prop_dist * 1e-6, experimental_setup=experimental_setup)\n",
    "    * np.exp(1j * phase)\n",
    ")\n",
    "\n",
    "# Create plot\n",
    "title = get_title(None, im_id, topo_id)\n",
    "plot_recon(recon[roi_s], title)\n",
    "\n",
    "# Save images\n",
    "fname = join(\n",
    "    folder_target,\n",
    "    \"Recon_ImId_%s_RefId_%s_%s.png\"\n",
    "    % (\n",
    "        im_id,\n",
    "        topo_id,\n",
    "        USER,\n",
    "    ),\n",
    ")\n",
    "print(\"Saving: %s\" % fname)\n",
    "plt.savefig(fname, bbox_inches=\"tight\", transparent=False)\n",
    "\n",
    "# Save hdf5 file\n",
    "save_fth_h5()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436c8f3a-213e-41a5-93e6-e6e857800b52",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Closes all existing plots\n",
    "plt.close(\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a449d5ad-ba40-4d7e-9dc8-60d46661fadb",
   "metadata": {},
   "source": [
    "# Load parameter from logfile"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fe865832-17d0-4944-8104-24ebc70ca50e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Define scans for each image\n",
    "# Images\n",
    "run_nr = \"run0001-test_axis\"\n",
    "acq_nr = 1\n",
    "im_id = list_acquisition_filenames(run_nr, acq_nr)\n",
    "\n",
    "# Topos\n",
    "run_nr = \"run0001-test_axis\"\n",
    "acq_nr = 2\n",
    "topo_id = list_acquisition_filenames(run_nr, acq_nr)\n",
    "\n",
    "# Define scan ids for each image\n",
    "dark_id = None\n",
    "\n",
    "print(\"Loading Image: %s\" % im_id)\n",
    "print(\"Loading Topo: %s\" % topo_id)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f19d1502-3676-4325-8bc0-c10d6847ea4d",
   "metadata": {
    "tags": []
   },
   "source": [
    "data = load_fth(im_id, topo_id)\n",
    "roi = data[\"roi\"]\n",
    "roi_s = np.s_[roi[0] : roi[1], roi[2] : roi[3]]\n",
    "center = data[\"center\"]\n",
    "prop_dist = data[\"prop_dist\"]\n",
    "phase = data[\"phase\"]\n",
    "mask_draw = data[\"mask_draw\"]\n",
    "mask_bs = data[\"mask_bs\"]\n",
    "mask_pixel = data[\"mask_pixel\"]\n",
    "mask_pixel_smooth = data[\"mask_pixel_smooth\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfa3a633-ce50-4f32-9a92-811404906742",
   "metadata": {},
   "source": [
    "# Batch processing FTH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b56aee-1b11-4aa0-a226-2094c28a474b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define Scans of each image\n",
    "im_id_set = [\"run0223*\"]\n",
    "topo_id_set = [\"run0221*\"]\n",
    "dark_id_set = [\"run0222*\"]\n",
    "\n",
    "# How many frame stacks to load in folder\n",
    "acq_nrs = np.arange(1, 50 + 1)\n",
    "LOADMODE = 16\n",
    "\n",
    "print(\"Loading Image: %s\" % im_id_set)\n",
    "print(\"Loading Topo: %s\" % topo_id_set)\n",
    "print(\"Loading Dark: %s\" % dark_id_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29bec12b-c6b2-4f64-a95a-9b55e4f6b74f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# less ugly Automatic processing of image stacks\n",
    "recons_name = []  # for gifs\n",
    "for it, im_id in enumerate(im_id_set):\n",
    "    # Load images\n",
    "    ids = list_acquisition_filenames(im_id, acq_nrs=[], ONLY_CAMERA=True)\n",
    "    image, _ = load_processing_frames(ids, loadmode=\"avg\", crop=0)\n",
    "\n",
    "    # Get topo\n",
    "    topo_id = topo_id_set[it]\n",
    "    ids = list_acquisition_filenames(topo_id, acq_nrs=[], ONLY_CAMERA=True)\n",
    "    topo, _ = load_processing_frames(ids, loadmode=\"avg\", crop=0)\n",
    "\n",
    "    # Load dark\n",
    "    dark_id = dark_id_set[it]\n",
    "    if dark_id is not None:\n",
    "        ids = list_acquisition_filenames(dark_id, acq_nrs=[], ONLY_CAMERA=True)\n",
    "        dark, _ = load_processing_frames(ids, loadmode=\"avg\", crop=0)\n",
    "        image = image - dark\n",
    "        topo = topo - dark\n",
    "\n",
    "    # Thresholding to prevent negative values\n",
    "    topo[topo < 1] = 0\n",
    "    image[image < 1] = 0\n",
    "\n",
    "    # Process images\n",
    "    worker_dict = worker(image, topo)\n",
    "\n",
    "    # Extract parameter from reco\n",
    "    recon = worker_dict[\"recon\"]\n",
    "    topo_c = worker_dict[\"topo_c\"]\n",
    "    sum_c = worker_dict[\"sum_c\"]\n",
    "    diff_c = worker_dict[\"diff_c\"]\n",
    "    im_c = worker_dict[\"im_c\"]\n",
    "    holo = worker_dict[\"diff_c\"]\n",
    "    shift = worker_dict[\"shift\"]\n",
    "    factor = worker_dict[\"factor\"]\n",
    "    offset = worker_dict[\"offset\"]\n",
    "\n",
    "    # Plot\n",
    "    title = get_title(None, im_id, topo_id, CDI=False)\n",
    "    plot_recon(recon[roi_s], title)\n",
    "\n",
    "    # Save images\n",
    "    fname = join(\n",
    "        folder_target,\n",
    "        \"Recon_ImId_%s_RefId_%s_%s_batch.png\"\n",
    "        % (\n",
    "            im_id,\n",
    "            topo_id,\n",
    "            USER,\n",
    "        ),\n",
    "    )\n",
    "    print(\"Saving: %s\" % fname)\n",
    "    plt.savefig(fname, bbox_inches=\"tight\", transparent=False)\n",
    "\n",
    "    # Optional: Save hdf5 file of fth data\n",
    "    save_fth_h5()\n",
    "\n",
    "    print(\" \")\n",
    "print(\"FTH stack processing finished\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e4cfdeb-0b43-4d67-88f8-6f8d83cbaa66",
   "metadata": {},
   "source": [
    "# CDI Reconstruction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51fe197c-911b-480c-8aa4-4e1d5820a5c9",
   "metadata": {},
   "source": [
    "## Create set of pos and neg helicity holograms\n",
    "\n",
    "CDI algorithm needs holograms recorded wih both helicity ($\\sigma = \\pm 1$) as input. We use will calculate those from our previously centered and intensity normalized holograms according to:\n",
    "\n",
    "$Image(\\sigma) = Topo + \\sigma \\cdot diff $,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b00b373-fbd1-441b-8a27-1861c82491b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Copy values from FTH reco (here topo = sum_c)\n",
    "pos = (im_c / factor).copy()\n",
    "neg = (topo_c).copy()\n",
    "# pos = (sum_c + diff_c) / 2\n",
    "# neg = (sum_c - diff_c) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139af7ff-9645-4010-b2a1-2643770f85d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Sharp mask on beamstop\n",
    "bs = interactive.InteractiveBeamstop(\n",
    "    im_c, im_c.shape[0] / 2, im_c.shape[1] / 2, rBS=50, stdBS=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebfd815a-cfa9-420d-a0bd-e7177da13840",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "mask_pixel_cdi = mask_pixel.copy() + mask_lib.circle_mask(im_c.shape, bs.center, bs.rBS)\n",
    "mask_pixel_cdi[mask_pixel_cdi > 1] = 1\n",
    "\n",
    "footprint = skimage.morphology.disk(6)\n",
    "mask_pixel_smooth = skimage.morphology.dilation(mask_pixel_cdi, footprint)\n",
    "mask_pixel_smooth = gaussian_filter(mask_pixel_smooth, 2)\n",
    "\n",
    "cimshow(mask_pixel_cdi * pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01af447b-ef22-4db8-b5bf-d9ae54694f2f",
   "metadata": {},
   "source": [
    "## Create Support mask\n",
    "\n",
    "The support mask is the real-space constraint used for the (holographically-aided) phase retrieval, i.e., certain details about our sample like the sample geometry. For our samples we can directly derive a very strong constraint: The FTH reconstructions show us previsely the actual real-space sample structure, i.e., the arrangement of our aperture where x-rays are transmitted (\"1\") while the masked areas show no transmission (\"0\"). We will therefore create a binary mask that reflects this transmission as an input for the phase retrieval.\n",
    "\n",
    "How to draw a support mask: Create a binary mask of the locations of sample apertures in the fth reconstruction. Areas with apertures are \"1\". Select only a single set of reconstructions (object & reference apertures) that originate from a single reference. Use the widget!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33ba5e51-02e4-42d4-8d39-335a82fb97f9",
   "metadata": {},
   "source": [
    "### Option 1: Execute if you want to create a new support mask with circle mask widget\n",
    "\n",
    "If you really want to create a new support mask, execute next cell and then the \"InteractiveCircleCoordinates\"-widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2c6350-0190-4e40-b1cd-20e300e149c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# How many references do you have?\n",
    "nr_ref = 4\n",
    "\n",
    "# Setup coordinates (nr_ref + 1 coordinates, as there is always the object aperture)\n",
    "support_coordinates = [\n",
    "    [pos.shape[-2] // 2, pos.shape[-1] // 2, 7] for k in range(nr_ref + 1)\n",
    "]\n",
    "\n",
    "# Widget to find the positions and sizes of the different apertures\n",
    "print(\n",
    "    \"Cover the object & reference apertures for each set of reconstructions that originates from the same reference with circles.\"\n",
    ")\n",
    "print(\n",
    "    \"Optimization: Change one circle parameter, calc phase retrieval image, compare with images reconstructed with old circle parameter. Repeat!\"\n",
    ")\n",
    "\n",
    "# Create plot\n",
    "holo = pos * mask_bs * (1 - mask_pixel_smooth)\n",
    "\n",
    "# Reconstruct\n",
    "recon = fth.reconstruct(\n",
    "    fth.propagate(holo, prop_dist * 1e-6, experimental_setup=experimental_setup)\n",
    "    * np.exp(1j * phase)\n",
    ")\n",
    "recon = np.real(recon)\n",
    "\n",
    "ds = interactive.InteractiveCircleCoordinates(\n",
    "    recon,\n",
    "    len(support_coordinates),\n",
    "    coordinates=support_coordinates.copy(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7579afc1-13c4-458d-9899-6261e412f47e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Take coordinates of circles from widget\n",
    "support_coordinates = ds.get_params()\n",
    "\n",
    "# Create supportmask from coordinates\n",
    "supportmask = mask_lib.create_circle_supportmask(support_coordinates, pos.shape)\n",
    "\n",
    "# Plot supportmask as overlay\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "mi, ma = np.percentile(recon, (1, 99))\n",
    "ax.imshow(recon, vmin=mi, vmax=ma, cmap=\"gray\")\n",
    "ax.imshow(supportmask, alpha=0.4, cmap=\"binary\")\n",
    "ax.set_title(\"Image with overlayed mask\")\n",
    "print(support_coordinates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c34cac-82b9-4ee1-adb4-a96bd5322b32",
   "metadata": {},
   "source": [
    "### Option 2: Execute if you want to load an existing support mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bcd9a51-aff9-483c-b6c7-1374246776d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_supportmask_coordinates(sample):\n",
    "    \"\"\"\n",
    "    Dictionary that stores coordinates of circular support mask apertures\n",
    "    \"\"\"\n",
    "\n",
    "    # Setup dictonary\n",
    "    support_coord = dict()\n",
    "\n",
    "    # coordinates\n",
    "    support_coord[\"Sample_41\"] = [\n",
    "        (1110.5, 774.0, 49.5),\n",
    "        (1020.0, 1024.0, 7.0),\n",
    "        (1217.0, 1014.0, 7.0),\n",
    "        (862.5, 878.5, 7.0),\n",
    "        (1368.0, 872.5, 6.0),\n",
    "    ]\n",
    "    support_coord[\"Felix\"] = [\n",
    "        (1185.0, 964.0, 43.0),\n",
    "        (1025.0, 891.0, 6.0),\n",
    "        (1122.0, 800.0, 6.0),\n",
    "        (1110.0, 1120.5, 6.0),\n",
    "        (1020.0, 1024.0, 6.0),\n",
    "    ]\n",
    "    support_coord[\"Sample_41_again\"] = [\n",
    "        (1110.5, 774.0, 47.5),\n",
    "        (1020.0, 1024.0, 7.0),\n",
    "        (1217.0, 1014.0, 7.0),\n",
    "        (862.5, 878.5, 7.0),\n",
    "        (1368.0, 872.5, 6.0),\n",
    "    ]\n",
    "    support_coord[\"Other_Boris_Sample\"] = [\n",
    "        (919.0, 775.5, 51.5),\n",
    "        (999.5, 742.5, 12.5),\n",
    "        (1000.5, 819.0, 7.5),\n",
    "        (1020.0, 1024.0, 6.0),\n",
    "    ]\n",
    "    support_coord[\"MFA_e22t\"] = [\n",
    "        (837.0, 1029.0, 16.5),\n",
    "        (751.0, 1053.0, 5.5),\n",
    "        (750.0, 1009.2, 6.0),\n",
    "        (717.5, 1031.5, 6.0),\n",
    "        (1002.5, 942.5, 6.0),\n",
    "        (1006.0, 1106.5, 5.0),\n",
    "        (1020.0, 1024.0, 5.0),\n",
    "    ]\n",
    "    support_coord[\"MFA_e22b\"] = [\n",
    "        (836.0, 1027.5, 18.0),\n",
    "        (749.0, 1051.0, 6.5),\n",
    "        (748.5, 1007.5, 6.5),\n",
    "        (716.0, 1030.0, 6.0),\n",
    "        (1002.5, 942.5, 5.5),\n",
    "        (1005.0, 1105.0, 5.0),\n",
    "        (1020.0, 1024.0, 5.0),\n",
    "    ]\n",
    "\n",
    "    support_coord[\"FB0023\"] = [\n",
    "        (1020.0, 1024.0, 5.0),\n",
    "        (927.0, 797.0, 4.5),\n",
    "        (1020.0, 890.5, 5.0),\n",
    "        (925.5, 1118.0, 5.0),\n",
    "        (857.0, 956.0, 45.0),\n",
    "    ]\n",
    "\n",
    "    support_coord[\"FB0023_square\"] = [\n",
    "        (1020.0, 1020.0, 5.0),\n",
    "        (926.5, 793.5, 5.5),\n",
    "        (1020.5, 887.5, 5.5),\n",
    "        (925.5, 1113.5, 5.0),\n",
    "        (857.5, 952.5, 44.0),\n",
    "    ]\n",
    "    support_coord[\"FB0023_square2\"] = [\n",
    "        (1020.0, 1020.0, 3.5),\n",
    "        (927.5, 793.5, 5.5),\n",
    "        (1021.0, 887.5, 5.5),\n",
    "        (926.0, 1113.5, 5.0),\n",
    "        (857.5, 952.5, 43.0),\n",
    "    ]\n",
    "\n",
    "    support_coord[\"FB0023_square2_sk\"] = [\n",
    "        (1020.0, 1024.0, 5.0),\n",
    "        (931.5, 793.0, 5.5),\n",
    "        (1023.5, 890.5, 5.5),\n",
    "        (923.0, 1116.5, 5.0),\n",
    "        (857.5, 952.5, 44.0),\n",
    "    ]\n",
    "\n",
    "    return support_coord[sample]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6da0ec-a9c9-4cdd-8f43-322937f3e721",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Which supportmask to load? (\"s2306a-C1\", \"s2308a-B1\", ...)\n",
    "sample = \"FB0023_square2_sk\"\n",
    "\n",
    "# Get coordinates and create supportmask\n",
    "support_coordinates = get_supportmask_coordinates(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48330d82-91cf-4b36-972b-b186df676ba3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Widget to find the positions and sizes of the different apertures\n",
    "print(\n",
    "    \"Cover the object & reference apertures for each set of reconstructions that originates from the same reference with circles.\"\n",
    ")\n",
    "print(\n",
    "    \"Optimization: Change one circle parameter, calc phase retrieval image, compare with images reconstructed with old circle parameter. Repeat!\"\n",
    ")\n",
    "\n",
    "# Plotting image\n",
    "holo = pos.copy()\n",
    "\n",
    "# Reconstruct\n",
    "recon = fth.reconstruct(\n",
    "    fth.propagate(holo, prop_dist * 1e-6, experimental_setup=experimental_setup)\n",
    "    * np.exp(1j * phase)\n",
    ")\n",
    "recon = np.abs(recon)\n",
    "\n",
    "ds = interactive.InteractiveCircleCoordinates(\n",
    "    recon,\n",
    "    len(support_coordinates),\n",
    "    coordinates=support_coordinates,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aeb3d91-dec4-45ee-ab63-3963ffc72f48",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Take coordinates of circles from widget\n",
    "support_coordinates = ds.get_params()\n",
    "\n",
    "# Create supportmask from coordinates\n",
    "supportmask = mask_lib.create_circle_supportmask(support_coordinates, pos.shape)\n",
    "\n",
    "# Plot supportmask as overlay\n",
    "fig, ax = plt.subplots(figsize=(6, 6))\n",
    "mi, ma = np.percentile(recon, (1, 99))\n",
    "ax.imshow(recon, vmin=mi, vmax=ma, cmap=\"gray\")\n",
    "ax.imshow(supportmask, alpha=0.4, cmap=\"binary\")\n",
    "ax.set_title(\"Image with overlayed mask\")\n",
    "print(support_coordinates)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b87865-8cc2-43cc-9633-1856f403a892",
   "metadata": {},
   "source": [
    "### Take Roi\n",
    "Choose the reconstructions as the ROI.\n",
    "\n",
    "1. Zoom into the image and adjust your FOV until you are satisfied.\n",
    "2. Save the axes coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1cacc82-1a63-4b59-99f1-a75fc6400faf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = cimshow(supportmask.astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ff5d31-51c8-4f7b-b2bc-5694041302be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "roi_cdi = interactive.axis_to_roi(ax)\n",
    "roi_cdi = [803, 914, 896, 1008]\n",
    "roi_cdi = np.s_[roi_cdi[0] : roi_cdi[1], roi_cdi[2] : roi_cdi[3]]\n",
    "print(\"Sliced roi:\", roi_cdi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49cbb580-9071-4687-bb51-c524d6dba155",
   "metadata": {},
   "source": [
    "## Do Phase Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50bd6fcd-3fbd-4a92-a22a-7ba7ff4c8c0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Lower boundary for subtraction of background [0,100]\n",
    "offset_vmin = 0.5\n",
    "\n",
    "# Options for initial guess\n",
    "# recon = fth.reconstruct(\n",
    "#    fth.propagate(pos, prop_dist * 1e-6, experimental_setup=experimental_setup)\n",
    "#    * np.exp(1j * phase)\n",
    "# )\n",
    "# Startimage = np.fft.fftshift(np.fft.ifft2(np.fft.ifftshift(recon * supportmask)))\n",
    "Startimage = None\n",
    "Startgamma = None\n",
    "\n",
    "# Executes algorithm\n",
    "(\n",
    "    retrieved_p,\n",
    "    retrieved_n,\n",
    "    retrieved_p_pc,\n",
    "    retrieved_n_pc,\n",
    "    bsmask_p,\n",
    "    bsmask_n,\n",
    "    gamma_p,\n",
    "    gamma_n,\n",
    ") = phase_retrieval(\n",
    "    pos,\n",
    "    neg,\n",
    "    mask_pixel_cdi.astype(int),\n",
    "    supportmask,\n",
    "    vmin=offset_vmin,\n",
    "    Startimage=Startimage,\n",
    "    Startgamma=Startgamma,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff1dc898-be45-419e-bca5-3c75b4531e8d",
   "metadata": {},
   "source": [
    "## Reconstruct images from phase retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f23af61-fd6d-4e96-82dc-ef4920018b74",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# New beamstop for CDI recos as phase retrieval of low-q might be insufficient. If phase retrieval worked well\n",
    "# Try without beamstop: `use_bs = False`\n",
    "use_bs = False\n",
    "bs_diam_cdi = 40  # diameter of beamstop\n",
    "\n",
    "# Create beamstop\n",
    "if use_bs is True:\n",
    "    mask_bs_cdi = 1 - mask_lib.circle_mask(\n",
    "        pos.shape, np.array(pos.shape) / 2, bs_diam_cdi, sigma=4\n",
    "    )\n",
    "    # mask_bs_cdi = 1 - mask_pixel_smooth.copy()\n",
    "elif use_bs is False:\n",
    "    mask_bs_cdi = np.ones(pos.shape)  # if you don't want a beamstop\n",
    "\n",
    "# Get Recos partial coherence\n",
    "# Positiv partial coherence\n",
    "p_pc = cci.reconstruct(\n",
    "    fth.propagate(\n",
    "        retrieved_p_pc * mask_bs_cdi,\n",
    "        prop_dist_cdi * 1e-6,\n",
    "        experimental_setup=experimental_setup,\n",
    "    )\n",
    ")\n",
    "\n",
    "# Negative partial coherence\n",
    "n_pc = cci.reconstruct(\n",
    "    fth.propagate(\n",
    "        retrieved_n_pc * mask_bs_cdi,\n",
    "        prop_dist_cdi * 1e-6,\n",
    "        experimental_setup=experimental_setup,\n",
    "    )\n",
    ")\n",
    "\n",
    "# optimize phase\n",
    "recon = p_pc - n_pc\n",
    "# _, phase_cdi = optimize_phase_contrast(\n",
    "#    recon, supportmask, method=\"contrast\", prefered_color=\"white\"\n",
    "# )\n",
    "\n",
    "# Plotting\n",
    "mode = \"-\"\n",
    "slider_prop, slider_phase, slider_dx, slider_dy = rec.focusCDI(\n",
    "    retrieved_p_pc * mask_bs_cdi,\n",
    "    retrieved_n_pc * mask_bs_cdi,\n",
    "    roi_cdi,\n",
    "    # mask=supportmask,\n",
    "    phase=phase_cdi,\n",
    "    dx=dx,\n",
    "    dy=dy,\n",
    "    prop_dist=prop_dist_cdi,\n",
    "    experimental_setup=experimental_setup,\n",
    "    operation=mode,\n",
    "    max_prop_dist=5,\n",
    "    scale=(0.1, 99.9),\n",
    ")\n",
    "print(\"Fine-tuning of reconstruction parameter:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c94f275-4c4f-4372-b0be-1480966d060a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Get phase from slider\n",
    "phase_cdi = slider_phase.value\n",
    "prop_dist_cdi = slider_prop.value\n",
    "\n",
    "# Reconstruct images with new parameter\n",
    "p_pc = fth.reconstructCDI(\n",
    "    fth.propagate(\n",
    "        retrieved_p_pc * mask_bs_cdi,\n",
    "        prop_dist_cdi * 1e-6,\n",
    "        experimental_setup=experimental_setup,\n",
    "    )\n",
    ") * np.exp(1j * phase_cdi)\n",
    "\n",
    "n_pc = fth.reconstructCDI(\n",
    "    fth.propagate(\n",
    "        retrieved_n_pc * mask_bs_cdi,\n",
    "        prop_dist_cdi * 1e-6,\n",
    "        experimental_setup=experimental_setup,\n",
    "    )\n",
    ") * np.exp(1j * phase_cdi)\n",
    "\n",
    "\n",
    "print(\"Phase CDI: %s\" % phase_cdi)\n",
    "print(\"Prop_dist: %s\" % prop_dist_cdi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f895ce-ed94-4905-ac73-744e0d96c413",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Confirm that offset subtraction in cdi function works, i.e., only small fraction of hologram is actually masked\n",
    "fig, ax = plt.subplots(2, 2, figsize=(8, 8), sharex=True, sharey=True)\n",
    "tmp = np.abs(retrieved_p_pc * mask_bs_cdi)\n",
    "mi, ma = np.percentile(tmp, [0.1, 99.9])\n",
    "ax[0, 0].imshow(tmp, vmin=mi, vmax=ma)\n",
    "ax[0, 0].set_title(\"Pos holo\")\n",
    "\n",
    "tmp = np.abs(retrieved_n_pc)\n",
    "mi, ma = np.percentile(tmp, [0.1, 99.9])\n",
    "ax[0, 1].imshow(tmp, vmin=mi, vmax=ma)\n",
    "ax[0, 1].set_title(\"Neg holo\")\n",
    "ax[1, 0].imshow(bsmask_p)\n",
    "ax[1, 0].set_title(\"Pos holo mask\")\n",
    "ax[1, 1].imshow(bsmask_n)\n",
    "ax[1, 1].set_title(\"Neg holo mask\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d6fa39-7e0f-48eb-b40b-aa4b6add1818",
   "metadata": {},
   "source": [
    "## Save reconstructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091dccc3-0336-4da8-be08-d4ad23f2cc56",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_recon(recon, title):\n",
    "    # Plot\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(10, 4))\n",
    "    fig.suptitle(title)\n",
    "\n",
    "    vmin, vmax = np.percentile(np.real(recon), (0.1, 99.9))\n",
    "    t_im1 = ax[0].imshow(np.real(recon), vmin=vmin, vmax=vmax, cmap=\"gray\")\n",
    "    ax[0].set_title(\"Real\")\n",
    "    plt.colorbar(t_im1, ax=ax[0], aspect=50)\n",
    "\n",
    "    vmin, vmax = np.percentile(np.imag(recon), (0.1, 99.9))\n",
    "    t_im2 = ax[1].imshow(np.imag(recon), vmin=vmin, vmax=vmax, cmap=\"gray\")\n",
    "    ax[1].set_title(\"Imag\")\n",
    "    plt.colorbar(t_im2, ax=ax[1], aspect=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc406438-f236-4afe-9c76-dbf9a639b2ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Saves only real and imaginary part\n",
    "# recon = p - n\n",
    "recon = p_pc - n_pc  #   / (p_pc + n_pc)\n",
    "\n",
    "# Plot\n",
    "title = get_title(None, im_id, topo_id, CDI=True)\n",
    "plot_recon(recon[roi_cdi], title)\n",
    "\n",
    "# Save images\n",
    "fname = join(\n",
    "    folder_target,\n",
    "    \"Recon_ImId_%s_RefId_%s_%s_diff_cdi.png\"\n",
    "    % (\n",
    "        im_id,\n",
    "        topo_id,\n",
    "        USER,\n",
    "    ),\n",
    ")\n",
    "print(\"Saving: %s\" % fname)\n",
    "plt.savefig(fname, bbox_inches=\"tight\", transparent=False)\n",
    "\n",
    "# Save h5\n",
    "save_cdi_h5()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d3fb869-451f-45a0-be0a-49883bb51f9d",
   "metadata": {},
   "source": [
    "# Batch processing CDI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41aa7caa-ad23-4bef-a9d1-31e20dfdb308",
   "metadata": {},
   "source": [
    "## Define Scan Ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688c3ce8-8a8e-4e37-b97a-dc5062e3648b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load support mask of which sample?\n",
    "sample = \"FB0023_square2_sk\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6bf8914-be4b-4263-8762-90099fee54a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the sets for reconstructions. You can make a list or use np.arange\n",
    "# im_id_set should always have ids of positive helicity holograms,\n",
    "# topo_id_set those of negative helicity or a hologram of a saturated state\n",
    "\n",
    "# You can also use nested lists: \n",
    "# in case topo_id_set = [[id1,id2],id3 it will use the sum hologram \n",
    "# calculated from [id1,id2] as topo\n",
    "\n",
    "im_id_set = [1755,1763,1774]\n",
    "dark_id_set = [1756,1762,1775]\n",
    "topo_id_set = [1757,1761,1776]\n",
    "\n",
    "# In case of single helicity reconstructions, adapt the helicity\n",
    "# for contrast inversion\n",
    "helicity = 1 * np.ones(len(im_id_set), dtype=int)  # [1,-1]\n",
    "\n",
    "print(\"Dynamics Set:  %s\" % im_id_set)\n",
    "print(\"Reference Set: %s\" % topo_id_set)\n",
    "print(\"Helicity: %s\" % helicity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1384901-c137-43a9-b53a-4c14befd1cab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define Scans of each image\n",
    "\n",
    "acq_nrs = np.arange(1, 50 + 1)  # [1, 2]\n",
    "LOADMODE = 16\n",
    "\n",
    "\n",
    "im_id_set = [199, 202]\n",
    "topo_id_set = [[201, 200], [201, 200]]\n",
    "dark_id_set = [183] * 40\n",
    "\n",
    "\n",
    "acq_nrs_im = np.arange(1, 1 + 1)\n",
    "acq_nrs_topo = np.arange(1, 50 + 1)\n",
    "acq_nrs_dark = np.arange(1, 10 + 1)\n",
    "\n",
    "\n",
    "for iii in range(len(im_id_set)):\n",
    "    if type(im_id_set[iii]) == list:\n",
    "        for jjj in range(len(im_id_set[iii])):\n",
    "            im_id_set[iii][jjj] = \"run%04d*\" % im_id_set[iii][jjj]\n",
    "    else:\n",
    "        im_id_set[iii] = \"run%04d*\" % im_id_set[iii]\n",
    "\n",
    "for iii in range(len(dark_id_set)):\n",
    "    dark_id_set[iii] = \"run%04d*\" % dark_id_set[iii]\n",
    "\n",
    "for iii in range(len(topo_id_set)):\n",
    "    if type(topo_id_set[iii]) == list:\n",
    "        for jjj in range(len(topo_id_set[iii])):\n",
    "            topo_id_set[iii][jjj] = \"run%04d*\" % topo_id_set[iii][jjj]\n",
    "    else:\n",
    "        topo_id_set[iii] = \"run%04d*\" % topo_id_set[iii]\n",
    "\n",
    "print(\"Loading Image: %s\" % im_id_set)\n",
    "print(\"Loading Topo: %s\" % topo_id_set)\n",
    "print(\"Loading Dark: %s\" % dark_id_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88cafe1a-54b4-42ae-a2d5-f8e5fd8ed6e6",
   "metadata": {},
   "source": [
    "## Execute Phase Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0182477-5d43-4554-b51e-f8bafbaebb32",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Ugly Automatic processing of image stacks\n",
    "recons_name = []  # for gifs\n",
    "for it, im_id in enumerate(tqdm(im_id_set)):\n",
    "    topo_id = topo_id_set[it]\n",
    "    dark_id = dark_id_set[it]\n",
    "\n",
    "    # Load image(s)\n",
    "    if isinstance(im_id, list):\n",
    "        image = []\n",
    "        for im_id2 in im_id:\n",
    "            ids = list_acquisition_filenames(im_id, acq_nrs=[], ONLY_CAMERA=True)\n",
    "            timage, _ = load_processing_frames(ids, loadmode=\"avg\", crop=0)\n",
    "            image.append(timage)\n",
    "        image = np.mean(np.array(image), axis=0)\n",
    "    else:\n",
    "        ids = list_acquisition_filenames(im_id, acq_nrs=[], ONLY_CAMERA=True)\n",
    "        image, _ = load_processing_frames(ids, loadmode=\"avg\", crop=0)\n",
    "\n",
    "    # Load dark\n",
    "    if dark_id is not None:\n",
    "        ids = list_acquisition_filenames(dark_id, acq_nrs=[], ONLY_CAMERA=True)\n",
    "        dark, _ = load_processing_frames(ids, loadmode=\"avg\", crop=0)\n",
    "    else:\n",
    "        dark = np.zeros_like(image)\n",
    "\n",
    "    # Subtract\n",
    "    image = image - dark\n",
    "\n",
    "    # Load topo\n",
    "    if isinstance(topo_id, list):\n",
    "        ids = list_acquisition_filenames(topo_id[0], acq_nrs=[], ONLY_CAMERA=True)\n",
    "        topop, _ = load_processing_frames(ids, loadmode=\"avg\", crop=0)\n",
    "        topop = topop - dark\n",
    "        ids = list_acquisition_filenames(topo_id[1], acq_nrs=[], ONLY_CAMERA=True)\n",
    "        topon, _ = load_processing_frames(ids, loadmode=\"avg\", crop=0)\n",
    "        topon = topon - dark\n",
    "        factor, offset = cci.dyn_factor(\n",
    "            topop,\n",
    "            topon,\n",
    "            method=\"correlation\",\n",
    "            print_out=False,\n",
    "            plot=False,\n",
    "        )\n",
    "        topo = (topop / factor + topon) / 2\n",
    "    else:\n",
    "        print(\"topo_id nolist\")\n",
    "        ids = list_acquisition_filenames(topo_id, acq_nrs=[], ONLY_CAMERA=True)\n",
    "        topo, _ = load_processing_frames(ids, loadmode=\"avg\", crop=0)\n",
    "        topo = topo - dark\n",
    "\n",
    "    # Process images\n",
    "    worker_dict = worker(image, topo)\n",
    "\n",
    "    # Extract parameter from reco\n",
    "    recon = worker_dict[\"recon\"]\n",
    "    topo_c = worker_dict[\"topo_c\"]\n",
    "    sum_c = worker_dict[\"sum_c\"]\n",
    "    diff_c = worker_dict[\"diff_c\"]\n",
    "    im_c = worker_dict[\"im_c\"]\n",
    "    holo = worker_dict[\"diff_c\"]\n",
    "    shift = worker_dict[\"shift\"]\n",
    "    factor = worker_dict[\"factor\"]\n",
    "    offset = worker_dict[\"offset\"]\n",
    "\n",
    "    # Plot\n",
    "    title = get_title(None, im_id, topo_id, CDI=False)\n",
    "    plot_recon(recon[roi_s], title)\n",
    "\n",
    "    # Save images\n",
    "    fname = join(\n",
    "        folder_target,\n",
    "        \"Recon_ImId_%s_RefId_%s_%s_batch.png\"\n",
    "        % (\n",
    "            im_id,\n",
    "            topo_id,\n",
    "            USER,\n",
    "        ),\n",
    "    )\n",
    "    print(\"Saving: %s\" % fname)\n",
    "    plt.savefig(fname, bbox_inches=\"tight\", transparent=False)\n",
    "\n",
    "    # Optional: Save hdf5 file of fth data\n",
    "    save_fth_h5()\n",
    "    save_topo_holo(topo_c, im_id, topo_id)\n",
    "\n",
    "    ################ CDI ###############\n",
    "    # Create pos and neg helicity set\n",
    "    pos = worker_dict[\"im_c\"] / worker_dict[\"factor\"]\n",
    "    neg = worker_dict[\"topo_c\"]\n",
    "    # pos = (worker_dict[\"sum_c\"] + worker_dict[\"diff_c\"]) / 2\n",
    "    # neg = (worker_dict[\"sum_c\"] - worker_dict[\"diff_c\"]) / 2\n",
    "\n",
    "    # Get coordinates and create supportmask\n",
    "    support_coordinates = get_supportmask_coordinates(sample)\n",
    "    supportmask = mask_lib.create_circle_supportmask(support_coordinates, pos.shape)\n",
    "\n",
    "    # Phase retrieval\n",
    "    Startimage = np.fft.fftshift(np.fft.ifft2(np.fft.ifftshift(supportmask)))\n",
    "    factor, offset = cci.dyn_factor(\n",
    "        np.abs(Startimage) * (1 - mask_pixel_cdi),\n",
    "        np.sqrt(np.maximum(pos, 0)) * (1 - mask_pixel_cdi),\n",
    "        method=\"correlation\",\n",
    "        print_out=False,\n",
    "        plot=False,\n",
    "        crop=100,\n",
    "    )\n",
    "    Startimage = Startimage / factor\n",
    "    Startgamma = None\n",
    "\n",
    "    # Do phase retrieval\n",
    "    (\n",
    "        retrieved_p,\n",
    "        retrieved_n,\n",
    "        retrieved_p_pc,\n",
    "        retrieved_n_pc,\n",
    "        bsmask_p,\n",
    "        bsmask_n,\n",
    "        gamma_p,\n",
    "        gamma_n,\n",
    "    ) = phase_retrieval(\n",
    "        pos,\n",
    "        neg,\n",
    "        mask_pixel_cdi,\n",
    "        supportmask,\n",
    "        vmin=offset_vmin,\n",
    "        Startimage=Startimage,\n",
    "        Startgamma=Startgamma,\n",
    "    )\n",
    "\n",
    "    # Get Recos partial coherence\n",
    "    # Positiv partial coherence\n",
    "    p_pc = fth.reconstructCDI(\n",
    "        fth.propagate(\n",
    "            retrieved_p_pc,\n",
    "            prop_dist_cdi * 1e-6,\n",
    "            experimental_setup=experimental_setup,\n",
    "        )\n",
    "    )\n",
    "    # Negative partial coherence\n",
    "    n_pc = fth.reconstructCDI(\n",
    "        fth.propagate(\n",
    "            retrieved_n_pc,\n",
    "            prop_dist_cdi * 1e-6,\n",
    "            experimental_setup=experimental_setup,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    ##### Calc reco and optimze contrast\n",
    "    # recon = helicity[it] * (p_pc - n_pc)\n",
    "    recon = p_pc - n_pc\n",
    "    # _, phase_cdi = optimize_phase_contrast(recon, supportmask, method=\"contrast\")\n",
    "    recon = recon * np.exp(1j * phase_cdi)\n",
    "    print(\"Phase is:\", np.round(phase_cdi, 2))\n",
    "\n",
    "    ########\n",
    "    # Plot\n",
    "    title = get_title(None, im_id, topo_id, CDI=True)\n",
    "    plot_recon(recon[roi_cdi], title)\n",
    "\n",
    "    # Save images\n",
    "    fname = join(\n",
    "        folder_target,\n",
    "        \"Recon_ImId_%s_RefId_%s_%s_cdi_batch.png\"\n",
    "        % (\n",
    "            im_id,\n",
    "            topo_id,\n",
    "            USER,\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    print(\"Saving: %s\" % fname)\n",
    "    plt.savefig(fname, bbox_inches=\"tight\", transparent=False)\n",
    "    recons_name.append(fname)\n",
    "\n",
    "    # Save files as h5\n",
    "    save_cdi_h5()\n",
    "\n",
    "    print(\" \")\n",
    "print(\"CDI stack processing finished\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8814afcc-ef8d-4d7a-8460-374eb018acad",
   "metadata": {},
   "source": [
    "#  Scratch"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "2404_SwissFEL",
   "language": "python",
   "name": "2404_swissfel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "toc-showcode": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
